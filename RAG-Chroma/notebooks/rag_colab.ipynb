{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47860ed4",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Quick Start: Download Sample Documents\n",
    "\n",
    "If you don't have documents ready, use these commands to download real examples:\n",
    "\n",
    "**Wikipedia Articles (Easy):**\n",
    "```bash\n",
    "# Download AI/ML Wikipedia articles\n",
    "!wget -O ml_article.txt https://raw.githubusercontent.com/wikipedia-dump/wikipedia-articles/main/machine_learning.txt\n",
    "!wget -O ai_article.txt https://raw.githubusercontent.com/wikipedia-dump/wikipedia-articles/main/artificial_intelligence.txt\n",
    "```\n",
    "\n",
    "**Scientific Papers:**\n",
    "```bash\n",
    "# Download arXiv papers as text\n",
    "!pip install arxiv\n",
    "!python -c \"import arxiv; paper = next(arxiv.Search(query='machine learning').results()); print(paper.download_pdf())\"\n",
    "```\n",
    "\n",
    "**Or use these pre-made sample files:**\n",
    "```python\n",
    "# Create sample documents automatically\n",
    "sample_docs = \"\"\"\n",
    "Machine learning is a branch of artificial intelligence that focuses on building systems \n",
    "that can learn from data. These systems improve their performance over time without being \n",
    "explicitly programmed. Common applications include recommendation systems, image recognition,\n",
    "natural language processing, and predictive analytics.\n",
    "\n",
    "Deep learning is a subset of machine learning based on artificial neural networks with \n",
    "multiple layers. These networks can automatically learn hierarchical representations of data.\n",
    "Popular architectures include CNNs for image processing, RNNs for sequential data, and \n",
    "Transformers for natural language understanding.\n",
    "\n",
    "Reinforcement learning is a type of machine learning where an agent learns to make decisions\n",
    "by interacting with an environment. The agent receives rewards or penalties and learns to \n",
    "maximize cumulative rewards. Applications include game playing, robotics, and autonomous systems.\n",
    "\"\"\".strip()\n",
    "\n",
    "with open('ml_basics.txt', 'w') as f:\n",
    "    f.write(sample_docs)\n",
    "    \n",
    "print(\"âœ… Sample document created: ml_basics.txt\")\n",
    "print(\"   You can now upload it in the next cell!\")\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5569207f",
   "metadata": {},
   "source": [
    "# ğŸ”§ RAG with ChromaDB - Self-Contained Notebook for Google Colab\n",
    "\n",
    "This notebook implements a complete **RAG (Retrieval-Augmented Generation)** system using:\n",
    "- **ChromaDB** as vector database\n",
    "- **Sentence Transformers** for embeddings\n",
    "- **Transformers (FLAN-T5)** for text generation\n",
    "\n",
    "âœ… **100% self-contained** - No external files required  \n",
    "âœ… **Optimized for Colab** - Works with free GPU\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ“š What is RAG?\n",
    "\n",
    "**RAG (Retrieval-Augmented Generation)** combines:\n",
    "1. **Retrieval**: Search for relevant documents in a knowledge base\n",
    "2. **Augmentation**: Use those documents as context\n",
    "3. **Generation**: Generate responses based on the retrieved context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896cec14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m915.7/915.7 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m149.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m145.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m139.1/139.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m188.3/188.3 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 2.8.6 requires torch<2.10,>=1.10, but you have torch 2.10.0 which is incompatible.\n",
      "cuda-python 12.9.5 requires cuda-bindings~=12.9.5, but you have cuda-bindings 12.9.4 which is incompatible.\n",
      "torchaudio 2.9.0+cu126 requires torch==2.9.0, but you have torch 2.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m131.1/131.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m109.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m17.4/17.4 MB\u001b[0m \u001b[31m121.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m132.6/132.6 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m220.0/220.0 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m131.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "opentelemetry-exporter-gcp-logging 1.11.0a0 requires opentelemetry-sdk<1.39.0,>=1.35.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
      "google-adk 1.21.0 requires opentelemetry-api<=1.37.0,>=1.37.0, but you have opentelemetry-api 1.39.1 which is incompatible.\n",
      "google-adk 1.21.0 requires opentelemetry-sdk<=1.37.0,>=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-exporter-otlp-proto-common==1.37.0, but you have opentelemetry-exporter-otlp-proto-common 1.39.1 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-proto==1.37.0, but you have opentelemetry-proto 1.39.1 which is incompatible.\n",
      "opentelemetry-exporter-otlp-proto-http 1.37.0 requires opentelemetry-sdk~=1.37.0, but you have opentelemetry-sdk 1.39.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "âœ… Installation completed!\n",
      "âš ï¸  IMPORTANT: Go to Runtime -> Restart runtime before continuing with the next cell\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“¦ Install dependencies (run only once)\n",
    "# IMPORTANT: After installing, go to Runtime -> Restart runtime before continuing\n",
    "\n",
    "!pip install -q torch torchvision --upgrade\n",
    "!pip install -q transformers==4.38.0 --no-deps\n",
    "!pip install -q tokenizers safetensors huggingface-hub\n",
    "!pip install -q sentence-transformers chromadb\n",
    "\n",
    "print(\"\\nâœ… Installation completed!\")\n",
    "print(\"âš ï¸  IMPORTANT: Go to Runtime -> Restart runtime before continuing with the next cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17811d82",
   "metadata": {},
   "source": [
    "### âš ï¸ IMPORTANT INSTRUCTIONS:\n",
    "1. Run the cell above â˜ï¸\n",
    "2. **Go to: Runtime â†’ Restart runtime**\n",
    "3. Continue with the next cell ğŸ‘‡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37918306",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£ Import Libraries and Configure GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfcdb6e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ–¥ï¸ Device: cuda\n",
      "ğŸ® GPU: Tesla T4\n",
      "ğŸ’¾ GPU Memory: 15.8 GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from typing import List, Dict, Any, Optional\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"ğŸ–¥ï¸ Device: {device}\")\n",
    "if device == \"cuda\":\n",
    "    print(f\"ğŸ® GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4a10fc",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Create Sample Documents\n",
    "\n",
    "Let's create a knowledge base about **Artificial Intelligence and Machine Learning**:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881c9c3a",
   "metadata": {},
   "source": [
    "## ğŸ“ Load Documents from Files (NEW)\n",
    "\n",
    "You can load your own text documents instead of using the predefined examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee19757",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import io\n",
    "import re\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 500, overlap: int = 50) -> list:\n",
    "    \"\"\"Split text into overlapping chunks.\"\"\"\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(0, len(words), chunk_size - overlap):\n",
    "        chunk = ' '.join(words[i:i + chunk_size])\n",
    "        if len(chunk.split()) >= 50:  # Only keep chunks with at least 50 words\n",
    "            chunks.append(chunk)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def load_txt_documents(chunk_size: int = 500, overlap: int = 50):\n",
    "    \"\"\"\n",
    "    Load and process text documents with automatic chunking.\n",
    "    \n",
    "    Args:\n",
    "        chunk_size: Number of words per chunk (default: 500)\n",
    "        overlap: Number of overlapping words between chunks (default: 50)\n",
    "    \"\"\"\n",
    "    print(\"ğŸ“¤ Select one or more .txt files to load...\")\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    documents = []\n",
    "    doc_id = 1\n",
    "    \n",
    "    for filename, content in uploaded.items():\n",
    "        try:\n",
    "            # Decode content\n",
    "            text = content.decode('utf-8')\n",
    "            \n",
    "            # Clean text\n",
    "            text = re.sub(r'\\s+', ' ', text)  # Remove extra spaces\n",
    "            text = text.strip()\n",
    "            \n",
    "            print(f\"\\nğŸ“„ Processing: {filename}\")\n",
    "            print(f\"   Original size: {len(text)} characters, {len(text.split())} words\")\n",
    "            \n",
    "            # Chunk the text\n",
    "            chunks = chunk_text(text, chunk_size, overlap)\n",
    "            \n",
    "            # Create document entries\n",
    "            for i, chunk in enumerate(chunks, 1):\n",
    "                documents.append({\n",
    "                    'id': f'doc_{doc_id}',\n",
    "                    'content': chunk,\n",
    "                    'metadata': {\n",
    "                        'source': filename,\n",
    "                        'chunk': i,\n",
    "                        'total_chunks': len(chunks),\n",
    "                        'category': 'uploaded'\n",
    "                    }\n",
    "                })\n",
    "                doc_id += 1\n",
    "            \n",
    "            print(f\"   âœ… Created {len(chunks)} chunks\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Error processing {filename}: {e}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Total: {len(documents)} document chunks loaded\")\n",
    "    return documents\n",
    "\n",
    "def load_from_url(url: str, chunk_size: int = 500):\n",
    "    \"\"\"Load text from a URL (Wikipedia, papers, etc.).\"\"\"\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    \n",
    "    print(f\"ğŸŒ Downloading from: {url}\")\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    # Extract text from paragraphs\n",
    "    paragraphs = soup.find_all('p')\n",
    "    text = ' '.join([p.get_text() for p in paragraphs])\n",
    "    \n",
    "    # Clean and chunk\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    chunks = chunk_text(text, chunk_size)\n",
    "    \n",
    "    documents = []\n",
    "    for i, chunk in enumerate(chunks, 1):\n",
    "        documents.append({\n",
    "            'id': f'web_doc_{i}',\n",
    "            'content': chunk,\n",
    "            'metadata': {\n",
    "                'source': url,\n",
    "                'chunk': i,\n",
    "                'total_chunks': len(chunks),\n",
    "                'category': 'web'\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    print(f\"âœ… Loaded {len(documents)} chunks from URL\")\n",
    "    return documents\n",
    "\n",
    "# Usage examples:\n",
    "print(\"ğŸ’¡ OPTION 1 - Load your own files:\")\n",
    "print(\"   my_docs = load_txt_documents(chunk_size=500)\")\n",
    "print(\"\\nğŸ’¡ OPTION 2 - Load from Wikipedia:\")\n",
    "print(\"   !pip install requests beautifulsoup4\")\n",
    "print(\"   docs = load_from_url('https://en.wikipedia.org/wiki/Machine_learning')\")\n",
    "print(\"\\nğŸ’¡ OPTION 3 - Load from Hugging Face dataset:\")\n",
    "print(\"   # See example in next cell\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638d80f5",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Load Real Documents\n",
    "\n",
    "Choose one of these options to load real documents:\n",
    "\n",
    "### ğŸ”¹ Option 1: Upload your own .txt files\n",
    "Supports PDFs, Word docs, or any text file. Automatically chunks long documents.\n",
    "\n",
    "### ğŸ”¹ Option 2: Download from Wikipedia\n",
    "Load any Wikipedia article directly from URL.\n",
    "\n",
    "### ğŸ”¹ Option 3: Use Hugging Face datasets\n",
    "Access thousands of pre-built datasets with scientific papers, books, articles, etc.\n",
    "\n",
    "### ğŸ”¹ Option 4: Download from these sources\n",
    "\n",
    "**For AI/ML content:**\n",
    "- arXiv papers: https://arxiv.org/list/cs.AI/recent\n",
    "- Research papers: https://paperswithcode.com/\n",
    "\n",
    "**For general content:**\n",
    "- Wikipedia: https://en.wikipedia.org\n",
    "- Project Gutenberg (books): https://www.gutenberg.org/\n",
    "- Common Crawl: https://commoncrawl.org/\n",
    "\n",
    "**ğŸ’¡ TIP**: Documents in **English** work best with FLAN-T5!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5f262f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CHOOSE ONE OF THESE OPTIONS TO LOAD REAL DOCUMENTS:\n",
    "# ============================================================\n",
    "\n",
    "# OPTION 1: Upload your own TXT files (EASIEST)\n",
    "# ----------------------------------------------\n",
    "# Just run this and select your files:\n",
    "DOCUMENTS = load_txt_documents(chunk_size=500, overlap=50)\n",
    "\n",
    "# OPTION 2: Load from Wikipedia (NO FILES NEEDED)\n",
    "# ------------------------------------------------\n",
    "# First install dependencies:\n",
    "# !pip install -q requests beautifulsoup4\n",
    "\n",
    "# Then load any Wikipedia article:\n",
    "# DOCUMENTS = load_from_url('https://en.wikipedia.org/wiki/Artificial_intelligence')\n",
    "# DOCUMENTS += load_from_url('https://en.wikipedia.org/wiki/Machine_learning')\n",
    "# DOCUMENTS += load_from_url('https://en.wikipedia.org/wiki/Deep_learning')\n",
    "\n",
    "# OPTION 3: Load from Hugging Face Dataset\n",
    "# ------------------------------------------\n",
    "# !pip install -q datasets\n",
    "\n",
    "# from datasets import load_dataset\n",
    "# dataset = load_dataset(\"wikipedia\", \"20220301.en\", split=\"train[:100]\")  # First 100 articles\n",
    "# DOCUMENTS = []\n",
    "# for i, item in enumerate(dataset):\n",
    "#     chunks = chunk_text(item['text'], chunk_size=500)\n",
    "#     for j, chunk in enumerate(chunks):\n",
    "#         DOCUMENTS.append({\n",
    "#             'id': f'wiki_{i}_{j}',\n",
    "#             'content': chunk,\n",
    "#             'metadata': {'source': item['title'], 'category': 'wikipedia'}\n",
    "#         })\n",
    "# print(f\"âœ… Loaded {len(DOCUMENTS)} chunks from Wikipedia dataset\")\n",
    "\n",
    "# OPTION 4: Load PDFs (requires extra library)\n",
    "# ---------------------------------------------\n",
    "# !pip install -q PyPDF2\n",
    "\n",
    "# from PyPDF2 import PdfReader\n",
    "# from google.colab import files\n",
    "# \n",
    "# print(\"ğŸ“¤ Upload PDF files...\")\n",
    "# uploaded = files.upload()\n",
    "# DOCUMENTS = []\n",
    "# doc_id = 1\n",
    "# \n",
    "# for filename, content in uploaded.items():\n",
    "#     pdf = PdfReader(io.BytesIO(content))\n",
    "#     text = ''\n",
    "#     for page in pdf.pages:\n",
    "#         text += page.extract_text()\n",
    "#     \n",
    "#     chunks = chunk_text(text, chunk_size=500)\n",
    "#     for i, chunk in enumerate(chunks, 1):\n",
    "#         DOCUMENTS.append({\n",
    "#             'id': f'doc_{doc_id}',\n",
    "#             'content': chunk,\n",
    "#             'metadata': {'source': filename, 'chunk': i}\n",
    "#         })\n",
    "#         doc_id += 1\n",
    "# \n",
    "# print(f\"âœ… Loaded {len(DOCUMENTS)} chunks from PDFs\")\n",
    "\n",
    "print(f\"\\nğŸ“š Total documents loaded: {len(DOCUMENTS)}\")\n",
    "print(f\"ğŸ” Sample document:\")\n",
    "print(f\"   Source: {DOCUMENTS[0]['metadata']['source']}\")\n",
    "print(f\"   Length: {len(DOCUMENTS[0]['content'])} characters\")\n",
    "print(f\"   Preview: {DOCUMENTS[0]['content'][:200]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dd39e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 10 documents loaded\n",
      "ğŸ“š Topics: ML, Neural Networks, Supervised/Unsupervised Learning, NLP, Computer Vision, RL, Transformers, Transfer Learning, RAG\n",
      "\n",
      "ğŸ” Sample document:\n",
      "   Machine learning is a subset of artificial intelligence that enables computers to learn from data wi...\n"
     ]
    }
   ],
   "source": [
    "# Sample knowledge base\n",
    "# IMPORTANT: FLAN-T5 works better with English documents\n",
    "\n",
    "DOCUMENTS = [\n",
    "    {\n",
    "        \"id\": \"doc_1\",\n",
    "        \"content\": \"Machine learning is a subset of artificial intelligence that enables computers to learn from data without being explicitly programmed. It uses algorithms to identify patterns in data and make predictions or decisions based on those patterns. Common applications include image recognition, spam filtering, and recommendation systems.\",\n",
    "        \"metadata\": {\"topic\": \"machine_learning\", \"category\": \"fundamentals\"}\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_2\",\n",
    "        \"content\": \"Neural networks are computing systems inspired by the biological neural networks in animal brains. They consist of layers of interconnected nodes (neurons) that process information. Deep neural networks with many layers are called deep learning models and have revolutionized fields like computer vision and natural language processing.\",\n",
    "        \"metadata\": {\"topic\": \"neural_networks\", \"category\": \"fundamentals\"}\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_3\",\n",
    "        \"content\": \"Supervised learning is a machine learning approach where the algorithm learns from labeled training data. The model is trained on input-output pairs and learns to map inputs to correct outputs. Examples include classification tasks like email spam detection and regression tasks like house price prediction.\",\n",
    "        \"metadata\": {\"topic\": \"supervised_learning\", \"category\": \"fundamentals\"}\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_4\",\n",
    "        \"content\": \"Unsupervised learning is a type of machine learning that finds patterns in data without labeled examples. The algorithm tries to find structure in unlabeled data through techniques like clustering and dimensionality reduction. Common applications include customer segmentation and anomaly detection.\",\n",
    "        \"metadata\": {\"topic\": \"unsupervised_learning\", \"category\": \"fundamentals\"}\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_5\",\n",
    "        \"content\": \"Natural Language Processing (NLP) is a branch of AI that helps computers understand, interpret, and generate human language. NLP techniques enable applications like machine translation, sentiment analysis, chatbots, and text summarization. Modern NLP relies heavily on deep learning models called transformers.\",\n",
    "        \"metadata\": {\"topic\": \"nlp\", \"category\": \"applications\"}\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_6\",\n",
    "        \"content\": \"Computer vision is a field of AI that enables computers to interpret and understand visual information from the world. It involves tasks like image classification, object detection, facial recognition, and image segmentation. Convolutional neural networks (CNNs) are particularly effective for computer vision tasks.\",\n",
    "        \"metadata\": {\"topic\": \"computer_vision\", \"category\": \"applications\"}\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_7\",\n",
    "        \"content\": \"Reinforcement learning is a machine learning paradigm where an agent learns to make decisions by interacting with an environment. The agent receives rewards or penalties based on its actions and learns to maximize cumulative rewards over time. Famous applications include game-playing AIs and robotics.\",\n",
    "        \"metadata\": {\"topic\": \"reinforcement_learning\", \"category\": \"fundamentals\"}\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_8\",\n",
    "        \"content\": \"Transformers are a type of neural network architecture that has revolutionized NLP. They use self-attention mechanisms to process sequential data in parallel, making them more efficient than previous recurrent architectures. Popular transformer models include BERT, GPT, and T5.\",\n",
    "        \"metadata\": {\"topic\": \"transformers\", \"category\": \"architectures\"}\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_9\",\n",
    "        \"content\": \"Transfer learning is a technique where a model trained on one task is reused as a starting point for a different but related task. This approach saves time and computational resources, as the model has already learned useful features from the first task. It's particularly effective when the new task has limited training data.\",\n",
    "        \"metadata\": {\"topic\": \"transfer_learning\", \"category\": \"techniques\"}\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_10\",\n",
    "        \"content\": \"Retrieval-Augmented Generation (RAG) is a technique that enhances language models by retrieving relevant information from a knowledge base before generating responses. This approach combines the benefits of information retrieval with text generation, producing more accurate and contextually relevant outputs. RAG systems are widely used in question-answering applications.\",\n",
    "        \"metadata\": {\"topic\": \"rag\", \"category\": \"techniques\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"âœ… {len(DOCUMENTS)} documents loaded\")\n",
    "print(f\"ğŸ“š Topics: ML, Neural Networks, Supervised/Unsupervised Learning, NLP, Computer Vision, RL, Transformers, Transfer Learning, RAG\")\n",
    "print(\"\\nğŸ” Sample document:\")\n",
    "print(f\"   {DOCUMENTS[0]['content'][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacd0f00",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Embeddings Class with Sentence Transformers\n",
    "\n",
    "We create a class that generates embeddings using Sentence Transformers models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8e65993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Loading embedding model: all-MiniLM-L6-v2...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d24d9592141b4e9fb51819611e082511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40a2d16ad2304c7abd3c4fa5536b8c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782b526c4d0d48d3916717eb6db2af30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c7b37686f449f6a0a73fbddce66bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a53facc86d54de1ae48ef120e72be64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e636b1d5b54d869d5003af7ac93ec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d335348594b44b884d7a71653af83e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a38ef7b5b6884b88be5acefd28eda891",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
      "WARNING:huggingface_hub.utils._http:Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1d0d6489dec4a26a85d3a75c6fa7330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7565b711a7694fccba62ef7ddb3b64d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ff77616d8884033960a87c4fc24c52b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "165eab27d6e04e649ee5675e997b0083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded - Dimension: 384\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingModel:\n",
    "    \"\"\"Generates embeddings using Sentence Transformers.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_name: Name of the Sentence Transformers model\n",
    "                       Options: all-MiniLM-L6-v2 (fast), all-mpnet-base-v2 (better quality)\n",
    "        \"\"\"\n",
    "        print(f\"ğŸ”„ Loading embedding model: {model_name}...\")\n",
    "        self.model = SentenceTransformer(model_name, device=device)\n",
    "        self.dimension = self.model.get_sentence_embedding_dimension()\n",
    "        print(f\"âœ… Model loaded - Dimension: {self.dimension}\")\n",
    "    \n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Generates embeddings for a list of texts.\"\"\"\n",
    "        embeddings = self.model.encode(texts, convert_to_numpy=True, show_progress_bar=True)\n",
    "        return embeddings.tolist()\n",
    "    \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Generates embedding for a single text (query).\"\"\"\n",
    "        embedding = self.model.encode(text, convert_to_numpy=True)\n",
    "        return embedding.tolist()\n",
    "\n",
    "# Create embedding model instance\n",
    "embedding_model = EmbeddingModel(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aca7267",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Create Vector Database with ChromaDB\n",
    "\n",
    "We configure ChromaDB to store and search our documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf6af56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Initializing ChromaDB...\n",
      "âœ… Collection 'ai_knowledge_base' created\n",
      "ğŸ”„ Generating embeddings for 10 documents...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aecbd06bd8c4018a05dcc9e530a04e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 10 documents added to the database\n",
      "\n",
      "ğŸ“Š Statistics: {'total_documents': 10, 'collection_name': 'ai_knowledge_base'}\n"
     ]
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Vector database using ChromaDB.\"\"\"\n",
    "    \n",
    "    def __init__(self, collection_name: str = \"rag_collection\"):\n",
    "        \"\"\"Initialize ChromaDB in memory (ideal for Colab).\"\"\"\n",
    "        print(\"ğŸ”„ Initializing ChromaDB...\")\n",
    "        self.client = chromadb.Client()  # In-memory client\n",
    "        \n",
    "        # Delete collection if exists (to allow re-running)\n",
    "        try:\n",
    "            self.client.delete_collection(collection_name)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        self.collection = self.client.create_collection(\n",
    "            name=collection_name,\n",
    "            metadata={\"hnsw:space\": \"cosine\"}  # Use cosine similarity\n",
    "        )\n",
    "        print(f\"âœ… Collection '{collection_name}' created\")\n",
    "    \n",
    "    def add_documents(self, documents: List[Dict], embedding_model: EmbeddingModel):\n",
    "        \"\"\"Add documents to the collection.\"\"\"\n",
    "        texts = [doc[\"content\"] for doc in documents]\n",
    "        ids = [doc[\"id\"] for doc in documents]\n",
    "        metadatas = [doc[\"metadata\"] for doc in documents]\n",
    "        \n",
    "        print(f\"ğŸ”„ Generating embeddings for {len(texts)} documents...\")\n",
    "        embeddings = embedding_model.embed_documents(texts)\n",
    "        \n",
    "        self.collection.add(\n",
    "            embeddings=embeddings,\n",
    "            documents=texts,\n",
    "            metadatas=metadatas,\n",
    "            ids=ids\n",
    "        )\n",
    "        print(f\"âœ… {len(documents)} documents added to the database\")\n",
    "    \n",
    "    def search(self, query: str, embedding_model: EmbeddingModel, \n",
    "               n_results: int = 3, filter_metadata: Optional[Dict] = None) -> Dict:\n",
    "        \"\"\"Search for documents similar to the query.\"\"\"\n",
    "        query_embedding = embedding_model.embed_query(query)\n",
    "        \n",
    "        results = self.collection.query(\n",
    "            query_embeddings=[query_embedding],\n",
    "            n_results=n_results,\n",
    "            where=filter_metadata,\n",
    "            include=[\"documents\", \"metadatas\", \"distances\"]\n",
    "        )\n",
    "        return results\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"Get collection statistics.\"\"\"\n",
    "        return {\n",
    "            \"total_documents\": self.collection.count(),\n",
    "            \"collection_name\": self.collection.name\n",
    "        }\n",
    "\n",
    "# Create vector database and add documents\n",
    "vector_store = VectorStore(\"ai_knowledge_base\")\n",
    "vector_store.add_documents(DOCUMENTS, embedding_model)\n",
    "print(f\"\\nğŸ“Š Statistics: {vector_store.get_stats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd0c68e",
   "metadata": {},
   "source": [
    "## 5ï¸âƒ£ Test Semantic Search\n",
    "\n",
    "Let's see how document retrieval works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac3b524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Query: 'What are transformers and how do they work?'\n",
      "------------------------------------------------------------\n",
      "\n",
      "  ğŸ“„ Result 1 (similarity: 0.569)\n",
      "     Topic: transformers\n",
      "     Text: Transformers are a type of neural network architecture that has revolutionized NLP. They use self-attention mechanisms to process sequential data in p...\n",
      "\n",
      "  ğŸ“„ Result 2 (similarity: 0.246)\n",
      "     Topic: transfer_learning\n",
      "     Text: Transfer learning is a technique where a model trained on one task is reused as a starting point for a different but related task. This approach saves...\n",
      "\n",
      "ğŸ” Query: 'How can I improve a pre-trained model?'\n",
      "------------------------------------------------------------\n",
      "\n",
      "  ğŸ“„ Result 1 (similarity: 0.312)\n",
      "     Topic: transfer_learning\n",
      "     Text: Transfer learning is a technique where a model trained on one task is reused as a starting point for a different but related task. This approach saves...\n",
      "\n",
      "  ğŸ“„ Result 2 (similarity: 0.224)\n",
      "     Topic: transformers\n",
      "     Text: Transformers are a type of neural network architecture that has revolutionized NLP. They use self-attention mechanisms to process sequential data in p...\n",
      "\n",
      "ğŸ” Query: 'What is RAG and what is it used for?'\n",
      "------------------------------------------------------------\n",
      "\n",
      "  ğŸ“„ Result 1 (similarity: 0.446)\n",
      "     Topic: rag\n",
      "     Text: Retrieval-Augmented Generation (RAG) is a technique that enhances language models by retrieving relevant information from a knowledge base before gene...\n",
      "\n",
      "  ğŸ“„ Result 2 (similarity: 0.163)\n",
      "     Topic: transfer_learning\n",
      "     Text: Transfer learning is a technique where a model trained on one task is reused as a starting point for a different but related task. This approach saves...\n"
     ]
    }
   ],
   "source": [
    "# Test semantic search\n",
    "test_queries = [\n",
    "    \"What are transformers and how do they work?\",\n",
    "    \"How can I improve a pre-trained model?\",\n",
    "    \"What is RAG and what is it used for?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\nğŸ” Query: '{query}'\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    results = vector_store.search(query, embedding_model, n_results=2)\n",
    "    \n",
    "    for i, (doc, metadata, distance) in enumerate(zip(\n",
    "        results['documents'][0], \n",
    "        results['metadatas'][0], \n",
    "        results['distances'][0]\n",
    "    )):\n",
    "        similarity = 1 - distance  # Convert distance to similarity\n",
    "        print(f\"\\n  ğŸ“„ Result {i+1} (similarity: {similarity:.3f})\")\n",
    "        print(f\"     Topic: {metadata['topic']}\")\n",
    "        print(f\"     Text: {doc[:150]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60f50f0",
   "metadata": {},
   "source": [
    "## 6ï¸âƒ£ Generator Model (FLAN-T5)\n",
    "\n",
    "We load a text generation model to answer questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20c157b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Loading generator model: google/flan-t5-base...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9bde29944e64790848104470c886191",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e55716560d9e47b388ad293e90435705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a22b08c50ab4d9b8a411d2fba96bb68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461b29a0e08e4fedba33fd5f708b1c90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7822b243a288442895e495f66a88b8fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a51480f77c4be083ebab7048a17963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/990M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27999593ca484bfcad7bb2c84be6df63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/282 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tied weights mapping and config for this model specifies to tie shared.weight to lm_head.weight, but both are present in the checkpoints, so we will NOT tie them. You should update the config with `tie_word_embeddings=False` to silence this warning\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a56e63bed63480ca9a5426b6ba95913",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded on cuda\n",
      "\n",
      "ğŸ’¡ TIP: If responses are not good, you can:\n",
      "   1. Use a larger model: google/flan-t5-large\n",
      "   2. Add more relevant documents\n",
      "   3. Ask more specific questions\n"
     ]
    }
   ],
   "source": [
    "class TextGenerator:\n",
    "    \"\"\"Text generator using FLAN-T5.\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name: str = \"google/flan-t5-base\"):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            model_name: Hugging Face model\n",
    "                       Options: google/flan-t5-small (fast), google/flan-t5-base (better)\n",
    "        \"\"\"\n",
    "        print(f\"ğŸ”„ Loading generator model: {model_name}...\")\n",
    "        \n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "            device_map=\"auto\" if device == \"cuda\" else None\n",
    "        )\n",
    "        \n",
    "        if device == \"cpu\":\n",
    "            self.model = self.model.to(device)\n",
    "        \n",
    "        print(f\"âœ… Model loaded on {device}\")\n",
    "    \n",
    "    def generate(self, prompt: str, max_length: int = 256) -> str:\n",
    "        \"\"\"Generate text from a prompt.\"\"\"\n",
    "        inputs = self.tokenizer(\n",
    "            prompt, \n",
    "            return_tensors=\"pt\", \n",
    "            max_length=512, \n",
    "            truncation=True\n",
    "        ).to(self.model.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_length=max_length,\n",
    "                min_length=20,\n",
    "                num_beams=4,\n",
    "                early_stopping=True,\n",
    "                no_repeat_ngram_size=3,\n",
    "                do_sample=False  # False for more coherence\n",
    "            )\n",
    "        \n",
    "        response = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        return response\n",
    "\n",
    "# Load generator model\n",
    "generator = TextGenerator(\"google/flan-t5-base\")\n",
    "\n",
    "print(\"\\nğŸ’¡ TIP: If responses are not good, you can:\")\n",
    "print(\"   1. Use a larger model: google/flan-t5-large\")\n",
    "print(\"   2. Add more relevant documents\")\n",
    "print(\"   3. Ask more specific questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a22f527",
   "metadata": {},
   "source": [
    "## 7ï¸âƒ£ Complete RAG System\n",
    "\n",
    "We combine everything into a functional RAG pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64a0ad22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RAG System initialized and ready!\n",
      "\n",
      "âš ï¸ IMPORTANT: FLAN-T5 works better with:\n",
      "   â€¢ Questions in ENGLISH\n",
      "   â€¢ Documents in ENGLISH\n",
      "   â€¢ Direct and simple questions\n"
     ]
    }
   ],
   "source": [
    "class RAGSystem:\n",
    "    \"\"\"Complete RAG system: Retrieval + Augmentation + Generation.\"\"\"\n",
    "    \n",
    "    def __init__(self, vector_store: VectorStore, embedding_model: EmbeddingModel, \n",
    "                 generator: TextGenerator):\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_model = embedding_model\n",
    "        self.generator = generator\n",
    "    \n",
    "    def build_prompt(self, question: str, context_docs: List[str]) -> str:\n",
    "        \"\"\"Build the prompt with context for the model.\"\"\"\n",
    "        # FLAN-T5 works better with simpler and more direct prompts\n",
    "        context = \"\\n\".join(context_docs)\n",
    "        \n",
    "        # Simplified format that works better with FLAN-T5\n",
    "        prompt = f\"\"\"Answer the question based on the context below.\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "Answer:\"\"\"\n",
    "        return prompt\n",
    "    \n",
    "    def query(self, question: str, n_docs: int = 3, verbose: bool = True) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Execute the complete RAG pipeline.\n",
    "        \n",
    "        Args:\n",
    "            question: User's question\n",
    "            n_docs: Number of documents to retrieve\n",
    "            verbose: Whether to show detailed information\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary with response, context and metadata\n",
    "        \"\"\"\n",
    "        # 1. RETRIEVAL - Search for relevant documents\n",
    "        if verbose:\n",
    "            print(f\"ğŸ” Searching for relevant documents...\")\n",
    "        \n",
    "        search_results = self.vector_store.search(\n",
    "            question, self.embedding_model, n_results=n_docs\n",
    "        )\n",
    "        \n",
    "        retrieved_docs = search_results['documents'][0]\n",
    "        metadatas = search_results['metadatas'][0]\n",
    "        distances = search_results['distances'][0]\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"ğŸ“„ {len(retrieved_docs)} documents found\")\n",
    "        \n",
    "        # 2. AUGMENTATION - Build prompt with context\n",
    "        prompt = self.build_prompt(question, retrieved_docs)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"ğŸ“ Prompt built ({len(prompt)} characters)\")\n",
    "        \n",
    "        # 3. GENERATION - Generate response\n",
    "        if verbose:\n",
    "            print(f\"ğŸ¤– Generating response...\")\n",
    "        \n",
    "        response = self.generator.generate(prompt, max_length=128)\n",
    "        \n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"answer\": response,\n",
    "            \"retrieved_documents\": retrieved_docs,\n",
    "            \"metadata\": metadatas,\n",
    "            \"similarity_scores\": [1 - d for d in distances],\n",
    "            \"prompt\": prompt\n",
    "        }\n",
    "\n",
    "# Create RAG system\n",
    "rag = RAGSystem(vector_store, embedding_model, generator)\n",
    "print(\"âœ… RAG System initialized and ready!\")\n",
    "print(\"\\nâš ï¸ IMPORTANT: FLAN-T5 works better with:\")\n",
    "print(\"   â€¢ Questions in ENGLISH\")\n",
    "print(\"   â€¢ Documents in ENGLISH\")\n",
    "print(\"   â€¢ Direct and simple questions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d683c7a",
   "metadata": {},
   "source": [
    "## 8ï¸âƒ£ Test the RAG System\n",
    "\n",
    "Let's ask some questions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e9c7086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test questions (in English for better FLAN-T5 performance)\n",
    "questions = [\n",
    "    \"What is machine learning?\",\n",
    "    \"How do neural networks work?\",\n",
    "    \"What is the difference between supervised and unsupervised learning?\",\n",
    "    \"What are transformers in NLP?\",\n",
    "    \"What is RAG and how does it work?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb181c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ“Œ QUESTION 1: What is machine learning?\n",
      "======================================================================\n",
      "ğŸ” Searching for relevant documents...\n",
      "ğŸ“„ 2 documents found\n",
      "ğŸ“ Prompt built (743 characters)\n",
      "ğŸ¤– Generating response...\n",
      "\n",
      "ğŸ’¡ ANSWER:\n",
      "   enables computers to learn without being explicitly programmed to learn from data without being explicit programmed\n",
      "\n",
      "ğŸ“š Documents used:\n",
      "   [1] (similarity: 0.802) Machine learning is a subset of artificial intelligence that enables computers to learn from data wi...\n",
      "   [2] (similarity: 0.685) Supervised learning is a machine learning approach where the algorithm learns from labeled training ...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Œ QUESTION 2: How do neural networks work?\n",
      "======================================================================\n",
      "ğŸ” Searching for relevant documents...\n",
      "ğŸ“„ 2 documents found\n",
      "ğŸ“ Prompt built (759 characters)\n",
      "ğŸ¤– Generating response...\n",
      "\n",
      "ğŸ’¡ ANSWER:\n",
      "   layers of interconnected nodes (neurons) that process information and have revolutionized fields like\n",
      "\n",
      "ğŸ“š Documents used:\n",
      "   [1] (similarity: 0.741) Neural networks are computing systems inspired by the biological neural networks in animal brains. T...\n",
      "   [2] (similarity: 0.472) Computer vision is a field of AI that enables computers to interpret and understand visual informati...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Œ QUESTION 3: What is the difference between supervised and unsupervised learning?\n",
      "======================================================================\n",
      "ğŸ” Searching for relevant documents...\n",
      "ğŸ“„ 2 documents found\n",
      "ğŸ“ Prompt built (753 characters)\n",
      "ğŸ¤– Generating response...\n",
      "\n",
      "ğŸ’¡ ANSWER:\n",
      "   Supervised learning is a machine learning approach where the algorithm learns from labeled training data. The model is trained on input-output\n",
      "\n",
      "ğŸ“š Documents used:\n",
      "   [1] (similarity: 0.695) Unsupervised learning is a type of machine learning that finds patterns in data without labeled exam...\n",
      "   [2] (similarity: 0.603) Supervised learning is a machine learning approach where the algorithm learns from labeled training ...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Œ QUESTION 4: What are transformers in NLP?\n",
      "======================================================================\n",
      "ğŸ” Searching for relevant documents...\n",
      "ğŸ“„ 2 documents found\n",
      "ğŸ“ Prompt built (696 characters)\n",
      "ğŸ¤– Generating response...\n",
      "\n",
      "ğŸ’¡ ANSWER:\n",
      "   type of neural network architecture that has revolutionized NLP. They use self-attention mechanisms to process sequential data in parallel\n",
      "\n",
      "ğŸ“š Documents used:\n",
      "   [1] (similarity: 0.748) Transformers are a type of neural network architecture that has revolutionized NLP. They use self-at...\n",
      "   [2] (similarity: 0.617) Natural Language Processing (NLP) is a branch of AI that helps computers understand, interpret, and ...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Œ QUESTION 5: What is RAG and how does it work?\n",
      "======================================================================\n",
      "ğŸ” Searching for relevant documents...\n",
      "ğŸ“„ 2 documents found\n",
      "ğŸ“ Prompt built (812 characters)\n",
      "ğŸ¤– Generating response...\n",
      "\n",
      "ğŸ’¡ ANSWER:\n",
      "   Retrieval-Augmented Generation (RAG) is a technique that enhances language models by retrieving relevant information\n",
      "\n",
      "ğŸ“š Documents used:\n",
      "   [1] (similarity: 0.438) Retrieval-Augmented Generation (RAG) is a technique that enhances language models by retrieving rele...\n",
      "   [2] (similarity: 0.181) Transfer learning is a technique where a model trained on one task is reused as a starting point for...\n"
     ]
    }
   ],
   "source": [
    "# Run RAG for each question\n",
    "for i, question in enumerate(questions, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"ğŸ“Œ QUESTION {i}: {question}\")\n",
    "    print('='*70)\n",
    "    \n",
    "    result = rag.query(question, n_docs=2, verbose=True)\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ ANSWER:\")\n",
    "    print(f\"   {result['answer']}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“š Documents used:\")\n",
    "    for j, (doc, score) in enumerate(zip(result['retrieved_documents'], \n",
    "                                          result['similarity_scores'])):\n",
    "        print(f\"   [{j+1}] (similarity: {score:.3f}) {doc[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c631f7c9",
   "metadata": {},
   "source": [
    "## 9ï¸âƒ£ Interactive Mode\n",
    "\n",
    "Ask your own questions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7caf563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â“ Your question: What is reinforcement learning?\n",
      "\n",
      "ğŸ” Searching for relevant documents...\n",
      "ğŸ“„ 3 documents found\n",
      "ğŸ“ Prompt built (1052 characters)\n",
      "ğŸ¤– Generating response...\n",
      "\n",
      "============================================================\n",
      "ğŸ’¡ ANSWER: an agent learns to make decisions by interacting with an environment. Reinforcement learning is a machine learning\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ Write your own question here (in English for best results)\n",
    "my_question = \"What is reinforcement learning?\"\n",
    "\n",
    "print(f\"â“ Your question: {my_question}\\n\")\n",
    "result = rag.query(my_question, n_docs=3, verbose=True)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ğŸ’¡ ANSWER: {result['answer']}\")\n",
    "print('='*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ba6526",
   "metadata": {},
   "source": [
    "## ğŸ”Ÿ Add New Documents\n",
    "\n",
    "You can expand the knowledge base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16da91bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Generating embeddings for 2 documents...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a36188c36c5c45b9bbfcdecc8e116a5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 2 documents added to the database\n",
      "\n",
      "ğŸ“Š Total documents: 12\n"
     ]
    }
   ],
   "source": [
    "# Add new documents\n",
    "new_docs = [\n",
    "    {\n",
    "        \"id\": \"doc_11\",\n",
    "        \"content\": \"\"\"AI agents are autonomous systems that can plan, reason, and execute \n",
    "        complex tasks. They use LLMs as their brain, combined with external tools, memory, \n",
    "        and reflection capabilities. Popular frameworks include LangChain Agents, AutoGPT, \n",
    "        and CrewAI.\"\"\",\n",
    "        \"metadata\": {\"topic\": \"agents\", \"category\": \"techniques\"}\n",
    "    },\n",
    "    {\n",
    "        \"id\": \"doc_12\",\n",
    "        \"content\": \"\"\"Prompting is the art of designing effective instructions for LLMs.\n",
    "        Techniques include: zero-shot (no examples), few-shot (with examples), \n",
    "        chain-of-thought (step-by-step reasoning), and role prompting (assigning roles).\n",
    "        A good prompt is clear, specific, and provides relevant context.\"\"\",\n",
    "        \"metadata\": {\"topic\": \"prompting\", \"category\": \"techniques\"}\n",
    "    }\n",
    "]\n",
    "\n",
    "vector_store.add_documents(new_docs, embedding_model)\n",
    "print(f\"\\nğŸ“Š Total documents: {vector_store.get_stats()['total_documents']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fb0e675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â“ What are AI agents and what frameworks exist?\n",
      "\n",
      "ğŸ” Searching for relevant documents...\n",
      "ğŸ“„ 2 documents found\n",
      "ğŸ“ Prompt built (698 characters)\n",
      "ğŸ¤– Generating response...\n",
      "\n",
      "ğŸ’¡ ANSWER: autonomous systems that can plan, reason, and execute complex tasks. They use LLMs as their brain\n"
     ]
    }
   ],
   "source": [
    "# Test with the new documents\n",
    "agents_question = \"What are AI agents and what frameworks exist?\"\n",
    "print(f\"â“ {agents_question}\\n\")\n",
    "\n",
    "result = rag.query(agents_question, n_docs=2, verbose=True)\n",
    "print(f\"\\nğŸ’¡ ANSWER: {result['answer']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13d8cbe",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£1ï¸âƒ£ Search with Metadata Filters\n",
    "\n",
    "You can filter documents by category or topic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e8b8deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Filtered search by category 'techniques':\n",
      "\n",
      "ğŸ“„ Topic: agents | Similarity: 0.422\n",
      "   AI agents are autonomous systems that can plan, reason, and execute \n",
      "        complex tasks. They use LLMs as their brain...\n",
      "\n",
      "ğŸ“„ Topic: transfer_learning | Similarity: 0.237\n",
      "   Transfer learning is a technique where a model trained on one task is reused as a starting point for a different but rel...\n",
      "\n",
      "ğŸ“„ Topic: prompting | Similarity: 0.188\n",
      "   Prompting is the art of designing effective instructions for LLMs.\n",
      "        Techniques include: zero-shot (no examples), ...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search only in documents of category \"techniques\"\n",
    "print(\"ğŸ” Filtered search by category 'techniques':\\n\")\n",
    "\n",
    "filtered_results = vector_store.search(\n",
    "    \"How to improve AI models?\",\n",
    "    embedding_model,\n",
    "    n_results=3,\n",
    "    filter_metadata={\"category\": \"techniques\"}\n",
    ")\n",
    "\n",
    "for doc, meta, dist in zip(\n",
    "    filtered_results['documents'][0],\n",
    "    filtered_results['metadatas'][0],\n",
    "    filtered_results['distances'][0]\n",
    "):\n",
    "    print(f\"ğŸ“„ Topic: {meta['topic']} | Similarity: {1-dist:.3f}\")\n",
    "    print(f\"   {doc[:120]}...\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0311c0",
   "metadata": {},
   "source": [
    "## 1ï¸âƒ£2ï¸âƒ£ RAG System Evaluation\n",
    "\n",
    "Basic metrics to evaluate quality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b4a1286f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š RETRIEVER EVALUATION\n",
      "==================================================\n",
      "âœ… 'What are transformers?...'\n",
      "   Expected: transformers | Found: ['transformers', 'transfer_learning', 'nlp']\n",
      "âœ… 'How does neural network learning work?...'\n",
      "   Expected: neural_networks | Found: ['neural_networks', 'supervised_learning', 'machine_learning']\n",
      "âœ… 'What is transfer learning?...'\n",
      "   Expected: transfer_learning | Found: ['transfer_learning', 'supervised_learning', 'reinforcement_learning']\n",
      "âœ… 'What are the types of machine learning?...'\n",
      "   Expected: machine_learning | Found: ['machine_learning', 'supervised_learning', 'unsupervised_learning']\n",
      "âœ… 'What is RAG?...'\n",
      "   Expected: rag | Found: ['rag', 'transfer_learning', 'transformers']\n",
      "\n",
      "ğŸ“ˆ METRICS:\n",
      "   Accuracy: 5/5 (100.0%)\n",
      "   MRR: 1.000\n"
     ]
    }
   ],
   "source": [
    "def evaluate_retrieval(query: str, expected_topic: str, n_results: int = 3) -> Dict:\n",
    "    \"\"\"Evaluate if the retriever finds documents of the expected topic.\"\"\"\n",
    "    results = vector_store.search(query, embedding_model, n_results=n_results)\n",
    "    \n",
    "    topics_found = [m['topic'] for m in results['metadatas'][0]]\n",
    "    hit = expected_topic in topics_found\n",
    "    position = topics_found.index(expected_topic) + 1 if hit else -1\n",
    "    \n",
    "    return {\n",
    "        \"query\": query,\n",
    "        \"expected\": expected_topic,\n",
    "        \"found_topics\": topics_found,\n",
    "        \"hit\": hit,\n",
    "        \"position\": position,\n",
    "        \"mrr\": 1/position if hit else 0  # Mean Reciprocal Rank\n",
    "    }\n",
    "\n",
    "# Test cases\n",
    "test_cases = [\n",
    "    (\"What are transformers?\", \"transformers\"),\n",
    "    (\"How does neural network learning work?\", \"neural_networks\"),\n",
    "    (\"What is transfer learning?\", \"transfer_learning\"),\n",
    "    (\"What are the types of machine learning?\", \"machine_learning\"),\n",
    "    (\"What is RAG?\", \"rag\"),\n",
    "]\n",
    "\n",
    "print(\"ğŸ“Š RETRIEVER EVALUATION\\n\" + \"=\"*50)\n",
    "eval_results = [evaluate_retrieval(q, t) for q, t in test_cases]\n",
    "\n",
    "total_hits = sum(1 for r in eval_results if r['hit'])\n",
    "avg_mrr = sum(r['mrr'] for r in eval_results) / len(eval_results)\n",
    "\n",
    "for r in eval_results:\n",
    "    status = \"âœ…\" if r['hit'] else \"âŒ\"\n",
    "    print(f\"{status} '{r['query'][:40]}...'\")\n",
    "    print(f\"   Expected: {r['expected']} | Found: {r['found_topics']}\")\n",
    "\n",
    "print(f\"\\nğŸ“ˆ METRICS:\")\n",
    "print(f\"   Accuracy: {total_hits}/{len(test_cases)} ({total_hits/len(test_cases)*100:.1f}%)\")\n",
    "print(f\"   MRR: {avg_mrr:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcec93a8",
   "metadata": {},
   "source": [
    "## ğŸ‰ Notebook Completed!\n",
    "\n",
    "### Summary of what we built:\n",
    "\n",
    "| Component | Description |\n",
    "|-----------|-------------|\n",
    "| **EmbeddingModel** | Generates semantic vectors with Sentence Transformers |\n",
    "| **VectorStore** | Vector database with ChromaDB |\n",
    "| **TextGenerator** | FLAN-T5 model for generating responses |\n",
    "| **RAGSystem** | Complete pipeline: Retrieval â†’ Augmentation â†’ Generation |\n",
    "\n",
    "### ğŸš€ Next steps:\n",
    "1. Add more documents to the knowledge base\n",
    "2. Try larger models (flan-t5-large, flan-t5-xl)\n",
    "3. Implement chunking for long documents\n",
    "4. Add reranking to improve precision\n",
    "5. Connect with external APIs (OpenAI, Anthropic)\n",
    "\n",
    "---\n",
    "**Created for the AI Mastery course** ğŸ“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aec044",
   "metadata": {},
   "source": [
    "## ğŸ”§ Troubleshooting\n",
    "\n",
    "### If responses are not good:\n",
    "\n",
    "**Option 1: Try a larger model**\n",
    "```python\n",
    "generator = TextGenerator(\"google/flan-t5-large\")  # Better quality but slower\n",
    "rag = RAGSystem(vector_store, embedding_model, generator)\n",
    "```\n",
    "\n",
    "**Option 2: Adjust generation parameters**\n",
    "```python\n",
    "# In the TextGenerator class, modify generate():\n",
    "outputs = self.model.generate(\n",
    "    **inputs,\n",
    "    max_length=256,        # Increase for longer responses\n",
    "    min_length=30,         # Minimum words\n",
    "    num_beams=6,           # More beams = better quality but slower\n",
    "    temperature=0.5,       # Between 0 and 1 (0=deterministic, 1=creative)\n",
    "    do_sample=True         # True for more variety\n",
    ")\n",
    "```\n",
    "\n",
    "**Option 3: Improve the prompt**\n",
    "```python\n",
    "# Modify build_prompt() in RAGSystem:\n",
    "prompt = f\"\"\"Based on the following context, answer the question concisely.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Provide a clear, factual answer based only on the context above:\n",
    "Answer:\"\"\"\n",
    "```\n",
    "\n",
    "**Option 4: Use retrieval only (without generation)**\n",
    "```python\n",
    "# If generation fails, at least you can see the relevant documents:\n",
    "results = vector_store.search(\"your question\", embedding_model, n_results=3)\n",
    "for doc in results['documents'][0]:\n",
    "    print(doc)\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
