{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "25081c55",
   "metadata": {},
   "source": [
    "# ðŸ”¬ BERT vs Qwen: Emotion Sentiment Analysis\n",
    "\n",
    "**Fine-tuning Pretrained Transformers for Sentiment Analysis (6 Emotion Classes)**\n",
    "\n",
    "This notebook compares **BERT** and **Qwen** on emotion classification using the official Emotion dataset from HuggingFace.\n",
    "\n",
    "## ðŸ“‹ Contents\n",
    "1. Setup & Dependencies\n",
    "2. Load Emotion Dataset (6 classes)\n",
    "3. Data Exploration\n",
    "4. Model Architecture\n",
    "5. Training Pipeline\n",
    "6. Fine-tune BERT\n",
    "7. Fine-tune Qwen\n",
    "8. **Performance Comparison**\n",
    "9. Inference Examples\n",
    "\n",
    "---\n",
    "\n",
    "| Aspect | Details |\n",
    "|--------|--------|\n",
    "| **Dataset** | Emotion (HuggingFace) |\n",
    "| **Classes** | 6 (sadness, joy, love, anger, fear, surprise) |\n",
    "| **Models** | BERT-base-uncased, Qwen2.5-0.5B |\n",
    "| **Task** | Sentiment/Emotion Classification |\n",
    "| **Colab** | âœ… GPU Recommended |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eecf8a92",
   "metadata": {},
   "source": [
    "## 1. ðŸ“¦ Setup & Dependencies\n",
    "\n",
    "Install all required packages for training transformer models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e556ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q transformers datasets torch accelerate scikit-learn matplotlib seaborn tqdm tabulate ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2322642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard libraries\n",
    "import os\n",
    "import gc\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import List, Dict, Optional, Tuple\n",
    "from dataclasses import dataclass, field\n",
    "from collections import defaultdict\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "\n",
    "# Transformers & Datasets\n",
    "from transformers import (\n",
    "    AutoModel,\n",
    "    AutoTokenizer,\n",
    "    AutoConfig,\n",
    "    get_linear_schedule_with_warmup,\n",
    "    get_cosine_schedule_with_warmup\n",
    ")\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    confusion_matrix,\n",
    "    classification_report\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Configure display settings\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "pd.set_option('display.max_colwidth', 100)\n",
    "\n",
    "# Print device info\n",
    "print(f\"PyTorch: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412b445a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Training configuration for emotion classification.\"\"\"\n",
    "    \n",
    "    # Dataset configuration\n",
    "    dataset_name: str = \"dair-ai/emotion\"  # HuggingFace dataset name (CORRECTED)\n",
    "    num_classes: int = 6  # Emotion dataset has 6 classes\n",
    "    class_names: List[str] = field(default_factory=lambda: [\n",
    "        \"sadness\", \"joy\", \"love\", \"anger\", \"fear\", \"surprise\"\n",
    "    ])\n",
    "    max_train_samples: int = 12000  # Use subset for faster training\n",
    "    max_test_samples: int = 2000\n",
    "    \n",
    "    # Model names\n",
    "    bert_model: str = \"bert-base-uncased\"\n",
    "    qwen_model: str = \"Qwen/Qwen2.5-0.5B\"\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    max_length: int = 128  # Max token length for input texts\n",
    "    batch_size: int = 16\n",
    "    epochs: int = 3\n",
    "    learning_rate: float = 2e-5\n",
    "    weight_decay: float = 0.01\n",
    "    warmup_ratio: float = 0.1\n",
    "    dropout: float = 0.1\n",
    "    \n",
    "    # Mixed precision training\n",
    "    use_amp: bool = True\n",
    "    \n",
    "    # Reproducibility\n",
    "    seed: int = 42\n",
    "\n",
    "\n",
    "# Initialize configuration\n",
    "config = Config()\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    \"\"\"Set random seeds for reproducibility across all libraries.\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "# Set seed and device\n",
    "set_seed(config.seed)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f\"\\nDevice: {device}\")\n",
    "print(f\"Classes ({config.num_classes}): {config.class_names}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f05b72d",
   "metadata": {},
   "source": [
    "## 2. ðŸ“Š Load Emotion Dataset from HuggingFace\n",
    "\n",
    "The Emotion dataset contains tweets labeled with 6 emotion categories.\n",
    "- **sadness** (0)\n",
    "- **joy** (1)\n",
    "- **love** (2)\n",
    "- **anger** (3)\n",
    "- **fear** (4)\n",
    "- **surprise** (5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f514dd84",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“š GuÃ­a Conceptual: AtenciÃ³n, MÃ©tricas y Fine-Tuning\n",
    "\n",
    "### ðŸ” Â¿QuÃ© es la AtenciÃ³n (Attention)?\n",
    "\n",
    "La **atenciÃ³n** es el mecanismo fundamental que permite a los modelos Transformer (como BERT y Qwen) entender el contexto y las relaciones entre palabras en un texto.\n",
    "\n",
    "#### **AnalogÃ­a Simple:**\n",
    "Imagina que estÃ¡s leyendo la frase: *\"El gato persiguiÃ³ al ratÃ³n porque **tenÃ­a** hambre\"*. \n",
    "- Â¿A quiÃ©n se refiere \"tenÃ­a\"? Â¿Al gato o al ratÃ³n?\n",
    "- Los humanos usamos el **contexto** para saber que \"tenÃ­a\" se refiere al \"gato\".\n",
    "- La **atenciÃ³n** permite que el modelo haga exactamente lo mismo: mirar otras palabras para entender cada palabra en contexto.\n",
    "\n",
    "#### **CÃ³mo Funciona TÃ©cnicamente:**\n",
    "\n",
    "```\n",
    "Texto: \"I love this movie\"\n",
    "         â†“\n",
    "Tokens:  [I] [love] [this] [movie]\n",
    "         â†“\n",
    "AtenciÃ³n: Cada token \"mira\" a todos los demÃ¡s\n",
    "         - \"love\" presta mÃ¡s atenciÃ³n a \"I\" (quiÃ©n ama)\n",
    "         - \"love\" tambiÃ©n mira a \"movie\" (quÃ© se ama)\n",
    "         - Crea una representaciÃ³n contextualizada\n",
    "```\n",
    "\n",
    "**En este cÃ³digo:**\n",
    "- `attention_mask`: Le dice al modelo quÃ© tokens son reales y cuÃ¡les son padding (relleno)\n",
    "- El modelo calcula automÃ¡ticamente los **pesos de atenciÃ³n** (quÃ© tan importante es cada palabra para entender otra)\n",
    "- Resultado: Cada palabra tiene una representaciÃ³n que incluye informaciÃ³n de todas las demÃ¡s\n",
    "\n",
    "#### **Tipos de AtenciÃ³n:**\n",
    "- **Self-Attention**: Una palabra se relaciona con otras en la misma oraciÃ³n (lo que usa este modelo)\n",
    "- **Cross-Attention**: Relaciona palabras entre dos secuencias diferentes (usado en traducciÃ³n)\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ“Š InterpretaciÃ³n de MÃ©tricas\n",
    "\n",
    "#### **1. Accuracy (PrecisiÃ³n General)**\n",
    "```\n",
    "Accuracy = (Predicciones Correctas) / (Total de Predicciones)\n",
    "```\n",
    "- **Ejemplo**: Si predecimos correctamente 900 de 1000 emociones â†’ Accuracy = 0.90 (90%)\n",
    "- **CuÃ¡ndo es Ãºtil**: Cuando todas las clases tienen similar importancia\n",
    "- **LimitaciÃ³n**: Si tienes 90% de \"alegrÃ­a\" y 10% de \"tristeza\", un modelo que siempre predice \"alegrÃ­a\" tendrÃ­a 90% accuracy pero serÃ­a inÃºtil\n",
    "\n",
    "#### **2. Precision (PrecisiÃ³n por Clase)**\n",
    "```\n",
    "Precision = Verdaderos Positivos / (Verdaderos Positivos + Falsos Positivos)\n",
    "```\n",
    "- **Pregunta que responde**: \"De todas las veces que predije 'tristeza', Â¿cuÃ¡ntas fueron realmente 'tristeza'?\"\n",
    "- **Ejemplo**: Predijimos \"anger\" 100 veces, pero solo 80 eran realmente \"anger\" â†’ Precision = 0.80\n",
    "- **Alta Precision significa**: Pocas falsas alarmas, el modelo es conservador\n",
    "\n",
    "#### **3. Recall (Exhaustividad)**\n",
    "```\n",
    "Recall = Verdaderos Positivos / (Verdaderos Positivos + Falsos Negativos)\n",
    "```\n",
    "- **Pregunta que responde**: \"De todos los textos que eran 'tristeza', Â¿cuÃ¡ntos detectamos?\"\n",
    "- **Ejemplo**: HabÃ­a 100 textos de \"fear\", pero solo detectamos 70 â†’ Recall = 0.70\n",
    "- **Alto Recall significa**: Detectamos la mayorÃ­a de casos, el modelo es exhaustivo\n",
    "\n",
    "#### **4. F1 Score (MÃ©trica Balanceada)** â­\n",
    "```\n",
    "F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)\n",
    "```\n",
    "- **Por quÃ© es importante**: Balancea precision y recall\n",
    "- **Ejemplo**:\n",
    "  - Modelo A: Precision=0.90, Recall=0.50 â†’ F1=0.64 (muy conservador)\n",
    "  - Modelo B: Precision=0.70, Recall=0.70 â†’ F1=0.70 (balanceado) âœ…\n",
    "  - Modelo C: Precision=0.50, Recall=0.90 â†’ F1=0.64 (detecta mucho pero con errores)\n",
    "\n",
    "**En este cÃ³digo**: Usamos **Weighted F1**, que promedia el F1 de cada clase ponderado por cuÃ¡ntos ejemplos hay de cada una.\n",
    "\n",
    "#### **ðŸ“ˆ CÃ³mo Interpretar los Resultados:**\n",
    "\n",
    "```\n",
    "BERT - TEST RESULTS\n",
    "========================================\n",
    "Accuracy:  0.9230  â† 92.3% de predicciones correctas\n",
    "Precision: 0.9245  â† 92.4% de las predicciones positivas son correctas\n",
    "Recall:    0.9230  â† Detectamos 92.3% de todos los casos reales\n",
    "F1 Score:  0.9232  â† MÃ©trica balanceada (MEJOR MÃ‰TRICA GENERAL)\n",
    "\n",
    "Per-emotion F1 scores:\n",
    "  sadness    F1: 0.8950  â† Modelo bueno detectando tristeza (89.5%)\n",
    "  joy        F1: 0.9650  â† Excelente con alegrÃ­a (96.5%)\n",
    "  love       F1: 0.7800  â† MÃ¡s difÃ­cil detectar amor (78%)\n",
    "  anger      F1: 0.9200  â† Muy bueno con enojo (92%)\n",
    "  fear       F1: 0.8500  â† Decente con miedo (85%)\n",
    "  surprise   F1: 0.9100  â† Excelente con sorpresa (91%)\n",
    "```\n",
    "\n",
    "**Â¿QuÃ© significa esto?**\n",
    "- **F1 > 0.90**: Excelente desempeÃ±o\n",
    "- **F1 = 0.80-0.90**: Muy bueno\n",
    "- **F1 = 0.70-0.80**: Aceptable, puede mejorar\n",
    "- **F1 < 0.70**: Necesita mejoras\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ¯ Fine-Tuning Explicado\n",
    "\n",
    "#### **Â¿QuÃ© es Fine-Tuning?**\n",
    "\n",
    "El **fine-tuning** es como tomar a un estudiante universitario (modelo preentrenado) y especializarlo para un trabajo especÃ­fico.\n",
    "\n",
    "**Fases del Modelo:**\n",
    "\n",
    "```\n",
    "1. PRE-ENTRENAMIENTO (Ya hecho por Google/Alibaba)\n",
    "   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "   â”‚ BERT/Qwen lee millones de textos   â”‚\n",
    "   â”‚ Aprende gramÃ¡tica, sintaxis,        â”‚\n",
    "   â”‚ relaciones semÃ¡nticas, etc.         â”‚\n",
    "   â”‚ Modelo: Conocimiento GENERAL        â”‚\n",
    "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "              â†“\n",
    "2. FINE-TUNING (Lo que hacemos aquÃ­) â­\n",
    "   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "   â”‚ Usamos el modelo preentrenado       â”‚\n",
    "   â”‚ Lo entrenamos con nuestros datos    â”‚\n",
    "   â”‚ (12,000 textos con emociones)       â”‚\n",
    "   â”‚ Modelo: Especialista en EMOCIONES   â”‚\n",
    "   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "#### **Â¿Por quÃ© funciona?**\n",
    "\n",
    "- **Sin Fine-Tuning**: Entrenar desde cero necesitarÃ­a millones de ejemplos y semanas de entrenamiento\n",
    "- **Con Fine-Tuning**: Aprovechamos el conocimiento previo y solo necesitamos miles de ejemplos y horas de entrenamiento\n",
    "\n",
    "#### **Componentes Clave en este CÃ³digo:**\n",
    "\n",
    "**1. Congelar vs Entrenar Capas:**\n",
    "```python\n",
    "# En este cÃ³digo NO congelamos capas (entrenamos todo)\n",
    "# Alternativa: Congelar transformer, solo entrenar clasificador\n",
    "for param in model.transformer.parameters():\n",
    "    param.requires_grad = False  # Esto congelarÃ­a\n",
    "```\n",
    "\n",
    "**2. Learning Rate (Tasa de Aprendizaje):**\n",
    "```python\n",
    "learning_rate: float = 2e-5  # â† MUY PEQUEÃ‘O\n",
    "```\n",
    "- **Por quÃ© pequeÃ±o**: El modelo ya sabe mucho, solo lo ajustamos ligeramente\n",
    "- **AnalogÃ­a**: No reescribimos el conocimiento, solo lo refinamos\n",
    "- **TÃ­pico**: 1e-5 a 5e-5 para fine-tuning\n",
    "\n",
    "**3. Epochs (Ã‰pocas):**\n",
    "```python\n",
    "epochs: int = 3  # â† POCAS Ã©pocas\n",
    "```\n",
    "- **Por quÃ© pocas**: El modelo converge rÃ¡pido porque ya estÃ¡ preentrenado\n",
    "- **MÃ¡s Ã©pocas**: Riesgo de overfitting (memorizar en lugar de aprender)\n",
    "\n",
    "**4. Warmup:**\n",
    "```python\n",
    "warmup_ratio: float = 0.1\n",
    "```\n",
    "- **QuÃ© hace**: Aumenta gradualmente el learning rate al inicio\n",
    "- **Por quÃ©**: Evita cambios bruscos que daÃ±en el conocimiento preentrenado\n",
    "- **AnalogÃ­a**: Como calentar antes de hacer ejercicio\n",
    "\n",
    "**5. Weight Decay:**\n",
    "```python\n",
    "weight_decay: float = 0.01\n",
    "```\n",
    "- **QuÃ© hace**: Penaliza pesos muy grandes (regularizaciÃ³n L2)\n",
    "- **Por quÃ©**: Evita overfitting, mantiene el modelo generalizable\n",
    "\n",
    "**6. Gradient Clipping:**\n",
    "```python\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "```\n",
    "- **QuÃ© hace**: Limita el tamaÃ±o mÃ¡ximo de los gradientes\n",
    "- **Por quÃ©**: Evita actualizaciones explosivas que arruinen el entrenamiento\n",
    "\n",
    "#### **Estrategias de Fine-Tuning:**\n",
    "\n",
    "| Estrategia | Capas Entrenadas | Datos Necesarios | Tiempo | Calidad |\n",
    "|------------|------------------|------------------|--------|---------|\n",
    "| **Feature Extraction** | Solo clasificador | Pocos (100s) | RÃ¡pido | BÃ¡sica |\n",
    "| **Partial Fine-Tuning** | Ãšltimas N capas | Moderados (1000s) | Medio | Buena |\n",
    "| **Full Fine-Tuning** â­ | Todas las capas | Muchos (10000s) | Lento | Mejor |\n",
    "\n",
    "**Este cÃ³digo usa Full Fine-Tuning** porque tenemos 12,000 ejemplos.\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ”¬ Entendiendo el Proceso de Entrenamiento\n",
    "\n",
    "#### **Lo que sucede en cada epoch:**\n",
    "\n",
    "```\n",
    "EPOCH 1:\n",
    "  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "  â”‚ 1. Forward Pass                     â”‚\n",
    "  â”‚    - Texto â†’ Tokens                 â”‚\n",
    "  â”‚    - Tokens â†’ Embeddings            â”‚\n",
    "  â”‚    - Attention layers               â”‚\n",
    "  â”‚    - Pooling â†’ Clasificador         â”‚\n",
    "  â”‚    - Output: PredicciÃ³n             â”‚\n",
    "  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "  â”‚ 2. Calcular Loss (Error)            â”‚\n",
    "  â”‚    - Compara predicciÃ³n vs real     â”‚\n",
    "  â”‚    - Cross Entropy Loss             â”‚\n",
    "  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "  â”‚ 3. Backward Pass                    â”‚\n",
    "  â”‚    - Calcula gradientes             â”‚\n",
    "  â”‚    - Identifica quÃ© cambiar         â”‚\n",
    "  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "  â”‚ 4. Optimizer Step                   â”‚\n",
    "  â”‚    - Actualiza pesos                â”‚\n",
    "  â”‚    - Mejora el modelo               â”‚\n",
    "  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "        â†“\n",
    "  ValidaciÃ³n: Â¿MejorÃ³ en datos no vistos?\n",
    "        â†“\n",
    "  Guardar si F1 mejorÃ³ âœ…\n",
    "```\n",
    "\n",
    "#### **Mixed Precision Training:**\n",
    "```python\n",
    "with autocast('cuda'):  # â† Usa FP16 (mÃ¡s rÃ¡pido)\n",
    "    outputs = model(input_ids, attention_mask)\n",
    "    loss = criterion(outputs, labels)\n",
    "```\n",
    "- **QuÃ© hace**: Usa nÃºmeros de 16 bits en lugar de 32 bits\n",
    "- **Beneficio**: 2x mÃ¡s rÃ¡pido, usa menos memoria\n",
    "- **Trade-off**: MÃ­nima pÃ©rdida de precisiÃ³n (no afecta resultados)\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸ’¡ Consejos PrÃ¡cticos\n",
    "\n",
    "#### **1. Si el modelo NO aprende (Loss no baja):**\n",
    "- Aumenta learning rate (1e-4)\n",
    "- Revisa que los datos estÃ©n bien etiquetados\n",
    "- Verifica que el modelo no estÃ© congelado\n",
    "\n",
    "#### **2. Si hay Overfitting (Train bien, Val mal):**\n",
    "- Aumenta dropout (0.2, 0.3)\n",
    "- Aumenta weight decay (0.05)\n",
    "- Reduce epochs\n",
    "- AÃ±ade mÃ¡s datos\n",
    "\n",
    "#### **3. Si hay Underfitting (Train y Val mal):**\n",
    "- Modelo muy simple â†’ Usa modelo mÃ¡s grande\n",
    "- Muy pocas epochs â†’ Entrena mÃ¡s tiempo\n",
    "- Learning rate muy bajo â†’ Aumenta a 3e-5\n",
    "\n",
    "#### **4. Para Mejorar Resultados:**\n",
    "- **Data Augmentation**: Parafrasear textos\n",
    "- **Ensemble**: Combinar BERT + Qwen predicciones\n",
    "- **Class Weights**: Balancear clases desbalanceadas\n",
    "- **Hyperparameter Tuning**: Probar diferentes configuraciones\n",
    "\n",
    "---\n",
    "\n",
    "### ðŸŽ“ Recursos para Profundizar\n",
    "\n",
    "- **Attention is All You Need**: Paper original de Transformers\n",
    "- **The Illustrated Transformer**: VisualizaciÃ³n del mecanismo de atenciÃ³n\n",
    "- **HuggingFace Course**: Tutorial completo de fine-tuning\n",
    "- **Jay Alammar's Blog**: Explicaciones visuales de BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9662d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD DATASET FROM HUGGINGFACE\n",
    "# ============================================================================\n",
    "\n",
    "print(\"Loading Emotion dataset from HuggingFace...\")\n",
    "print(\"Note: Dataset is public and does not require authentication.\")\n",
    "\n",
    "# Load dataset with correct name\n",
    "dataset = load_dataset(\"dair-ai/emotion\")\n",
    "\n",
    "print(f\"\\nDataset structure:\")\n",
    "print(dataset)\n",
    "\n",
    "# Create train/val/test split\n",
    "train_dataset = dataset['train'].shuffle(seed=config.seed).select(range(config.max_train_samples))\n",
    "test_split = dataset['test'].shuffle(seed=config.seed).select(range(config.max_test_samples))\n",
    "\n",
    "# Split test into validation and test (50-50)\n",
    "test_val_split = test_split.train_test_split(test_size=0.5, seed=config.seed)\n",
    "val_dataset = test_val_split['train']\n",
    "test_dataset = test_val_split['test']\n",
    "\n",
    "print(f\"\\nâœ“ Dataset loaded successfully!\")\n",
    "print(f\"  Training samples: {len(train_dataset)}\")\n",
    "print(f\"  Validation samples: {len(val_dataset)}\")\n",
    "print(f\"  Test samples: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5e9833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample data from each emotion class\n",
    "print(\"\\nSample texts from each emotion:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for emotion_id, emotion_name in enumerate(config.class_names):\n",
    "    # Find first example of this emotion\n",
    "    sample = [s for s in train_dataset if s['label'] == emotion_id][0]\n",
    "    print(f\"\\n[{emotion_name.upper()}]\")\n",
    "    print(f\"  Text: {sample['text']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a85339f",
   "metadata": {},
   "source": [
    "## 3. ðŸ“ˆ Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40162fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for analysis\n",
    "train_df = pd.DataFrame({\n",
    "    'text': train_dataset['text'],\n",
    "    'label': train_dataset['label'],\n",
    "    'emotion': [config.class_names[l] for l in train_dataset['label']]\n",
    "})\n",
    "\n",
    "# Add text statistics\n",
    "train_df['word_count'] = train_df['text'].str.split().str.len()\n",
    "train_df['char_count'] = train_df['text'].str.len()\n",
    "\n",
    "print(\"Dataset Statistics:\")\n",
    "print(train_df.groupby('emotion')[['word_count', 'char_count']].describe().round(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b9e6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Class distribution, word count distribution\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# 1. Class Distribution\n",
    "colors = ['#e74c3c', '#3498db', '#2ecc71', '#9b59b6', '#f39c12', '#1abc9c']\n",
    "emotion_counts = train_df['emotion'].value_counts()\n",
    "axes[0].bar(emotion_counts.index, emotion_counts.values, color=colors)\n",
    "axes[0].set_title('Emotion Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# 2. Word Count Distribution by Emotion\n",
    "for i, (emotion, group) in enumerate(train_df.groupby('emotion')):\n",
    "    axes[1].hist(group['word_count'], bins=30, alpha=0.6, label=emotion, color=colors[i])\n",
    "axes[1].set_title('Word Count Distribution', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Word Count')\n",
    "axes[1].legend(fontsize=8)\n",
    "\n",
    "# 3. Boxplot of Word Counts\n",
    "train_df.boxplot(column='word_count', by='emotion', ax=axes[2])\n",
    "axes[2].set_title('Word Count by Emotion', fontsize=14, fontweight='bold')\n",
    "axes[2].set_xlabel('Emotion')\n",
    "axes[2].set_ylabel('Word Count')\n",
    "plt.suptitle('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf07503",
   "metadata": {},
   "source": [
    "## 4. ðŸ—ï¸ Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8acf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PYTORCH DATASET CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class TextClassificationDataset(Dataset):\n",
    "    \"\"\"PyTorch Dataset for emotion classification.\"\"\"\n",
    "    \n",
    "    def __init__(self, texts: List[str], labels: List[int], tokenizer, max_length: int = 128):\n",
    "        \"\"\"Initialize dataset.\n",
    "        \n",
    "        Args:\n",
    "            texts: List of input texts\n",
    "            labels: List of label indices\n",
    "            tokenizer: Pretrained tokenizer\n",
    "            max_length: Maximum sequence length\n",
    "        \"\"\"\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"Get single sample.\"\"\"\n",
    "        text = str(self.texts[idx])\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        # Tokenize text\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad29586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRANSFORMER CLASSIFIER\n",
    "# ============================================================================\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    \"\"\"Unified classifier for BERT and Qwen models.\n",
    "    \n",
    "    This module:\n",
    "    - Loads pretrained transformer models\n",
    "    - Applies pooling (CLS for BERT, Mean for Qwen)\n",
    "    - Uses multi-layer classification head\n",
    "    - Supports dropout for regularization\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_name: str,\n",
    "        num_classes: int,\n",
    "        dropout: float = 0.1,\n",
    "        pooling: str = \"auto\",\n",
    "        trust_remote_code: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        \n",
    "        # Auto-select pooling strategy based on model\n",
    "        if pooling == \"auto\":\n",
    "            self.pooling = \"mean\" if \"qwen\" in model_name.lower() else \"cls\"\n",
    "        else:\n",
    "            self.pooling = pooling\n",
    "        \n",
    "        # Load model config and weights\n",
    "        self.config = AutoConfig.from_pretrained(\n",
    "            model_name,\n",
    "            trust_remote_code=trust_remote_code\n",
    "        )\n",
    "        \n",
    "        # Load model in FP32 - AMP will handle mixed precision automatically\n",
    "        self.transformer = AutoModel.from_pretrained(\n",
    "            model_name,\n",
    "            trust_remote_code=trust_remote_code\n",
    "        )\n",
    "        \n",
    "        hidden_size = self.config.hidden_size\n",
    "        \n",
    "        # Classification head (multi-layer)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size, hidden_size // 2),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(hidden_size // 2),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
    "            nn.GELU(),\n",
    "            nn.LayerNorm(hidden_size // 4),\n",
    "            nn.Dropout(dropout / 2),\n",
    "            nn.Linear(hidden_size // 4, num_classes)\n",
    "        )\n",
    "        \n",
    "        self._init_weights()\n",
    "    \n",
    "    def _init_weights(self):\n",
    "        \"\"\"Initialize classifier layer weights using Xavier initialization.\"\"\"\n",
    "        for module in self.classifier.modules():\n",
    "            if isinstance(module, nn.Linear):\n",
    "                nn.init.xavier_uniform_(module.weight)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "    \n",
    "    def _pool(self, hidden_states: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Apply pooling strategy to get sentence representation.\n",
    "        \n",
    "        Args:\n",
    "            hidden_states: [batch_size, seq_length, hidden_size]\n",
    "            attention_mask: [batch_size, seq_length]\n",
    "            \n",
    "        Returns:\n",
    "            pooled: [batch_size, hidden_size]\n",
    "        \"\"\"\n",
    "        if self.pooling == \"cls\":\n",
    "            # Use [CLS] token (first token)\n",
    "            return hidden_states[:, 0, :]\n",
    "        elif self.pooling == \"mean\":\n",
    "            # Mean pooling with attention mask\n",
    "            mask = attention_mask.unsqueeze(-1).expand(hidden_states.size()).float()\n",
    "            sum_hidden = torch.sum(hidden_states * mask, dim=1)\n",
    "            sum_mask = torch.clamp(mask.sum(dim=1), min=1e-9)\n",
    "            return sum_hidden / sum_mask\n",
    "        else:\n",
    "            return hidden_states[:, 0, :]\n",
    "    \n",
    "    def forward(self, input_ids: torch.Tensor, attention_mask: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Forward pass.\n",
    "        \n",
    "        Args:\n",
    "            input_ids: [batch_size, seq_length]\n",
    "            attention_mask: [batch_size, seq_length]\n",
    "            \n",
    "        Returns:\n",
    "            logits: [batch_size, num_classes]\n",
    "        \"\"\"\n",
    "        # Get transformer output\n",
    "        outputs = self.transformer(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        # Get hidden states\n",
    "        hidden_states = outputs.last_hidden_state\n",
    "        \n",
    "        # Apply pooling\n",
    "        pooled = self._pool(hidden_states, attention_mask)\n",
    "        \n",
    "        # Ensure float32 for classifier (important for mixed precision)\n",
    "        pooled = pooled.float()\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(pooled)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e5e7fb",
   "metadata": {},
   "source": [
    "## 5. ðŸ”§ Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b46a60be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# TRAINER CLASS\n",
    "# ============================================================================\n",
    "\n",
    "class Trainer:\n",
    "    \"\"\"Unified trainer for BERT and Qwen with mixed precision and scheduling.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        train_loader: DataLoader,\n",
    "        val_loader: DataLoader,\n",
    "        config: Config,\n",
    "        device: torch.device,\n",
    "        model_name: str = \"model\"\n",
    "    ):\n",
    "        \"\"\"Initialize trainer.\"\"\"\n",
    "        self.model = model\n",
    "        self.train_loader = train_loader\n",
    "        self.val_loader = val_loader\n",
    "        self.config = config\n",
    "        self.device = device\n",
    "        self.model_name = model_name\n",
    "        \n",
    "        # Loss function for multi-class classification\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "        # Optimizer with weight decay\n",
    "        self.optimizer = self._create_optimizer()\n",
    "        \n",
    "        # Learning rate scheduler (cosine with warmup)\n",
    "        num_training_steps = len(train_loader) * config.epochs\n",
    "        num_warmup_steps = int(num_training_steps * config.warmup_ratio)\n",
    "        self.scheduler = get_cosine_schedule_with_warmup(\n",
    "            self.optimizer,\n",
    "            num_warmup_steps=num_warmup_steps,\n",
    "            num_training_steps=num_training_steps\n",
    "        )\n",
    "        \n",
    "        # Mixed precision training (updated API)\n",
    "        self.scaler = GradScaler('cuda') if config.use_amp and torch.cuda.is_available() else None\n",
    "        \n",
    "        # Training history\n",
    "        self.history = defaultdict(list)\n",
    "        self.best_val_f1 = 0\n",
    "        self.training_time = 0\n",
    "    \n",
    "    def _create_optimizer(self):\n",
    "        \"\"\"Create AdamW optimizer with weight decay discrimination.\"\"\"\n",
    "        no_decay = ['bias', 'LayerNorm.weight', 'LayerNorm.bias', 'layer_norm']\n",
    "        optimizer_grouped_parameters = [\n",
    "            {\n",
    "                'params': [p for n, p in self.model.named_parameters() \n",
    "                          if not any(nd in n for nd in no_decay) and p.requires_grad],\n",
    "                'weight_decay': self.config.weight_decay\n",
    "            },\n",
    "            {\n",
    "                'params': [p for n, p in self.model.named_parameters() \n",
    "                          if any(nd in n for nd in no_decay) and p.requires_grad],\n",
    "                'weight_decay': 0.0\n",
    "            }\n",
    "        ]\n",
    "        return torch.optim.AdamW(optimizer_grouped_parameters, lr=self.config.learning_rate)\n",
    "    \n",
    "    def train_epoch(self) -> Tuple[float, float]:\n",
    "        \"\"\"Train for one epoch.\"\"\"\n",
    "        self.model.train()\n",
    "        total_loss = 0\n",
    "        all_preds, all_labels = [], []\n",
    "        \n",
    "        pbar = tqdm(self.train_loader, desc=f\"Training {self.model_name}\")\n",
    "        \n",
    "        for batch in pbar:\n",
    "            input_ids = batch['input_ids'].to(self.device)\n",
    "            attention_mask = batch['attention_mask'].to(self.device)\n",
    "            labels = batch['labels'].to(self.device)\n",
    "            \n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass with mixed precision (updated API)\n",
    "            if self.scaler:\n",
    "                with autocast('cuda'):\n",
    "                    outputs = self.model(input_ids, attention_mask)\n",
    "                    loss = self.criterion(outputs, labels)\n",
    "                \n",
    "                self.scaler.scale(loss).backward()\n",
    "                self.scaler.unscale_(self.optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                self.scaler.step(self.optimizer)\n",
    "                self.scaler.update()\n",
    "            else:\n",
    "                outputs = self.model(input_ids, attention_mask)\n",
    "                loss = self.criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)\n",
    "                self.optimizer.step()\n",
    "            \n",
    "            self.scheduler.step()\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        avg_loss = total_loss / len(self.train_loader)\n",
    "        accuracy = accuracy_score(all_labels, all_preds)\n",
    "        \n",
    "        return avg_loss, accuracy\n",
    "    \n",
    "    @torch.no_grad()\n",
    "    def evaluate(self, dataloader: DataLoader) -> Dict:\n",
    "        \"\"\"Evaluate model on a dataset.\"\"\"\n",
    "        self.model.eval()\n",
    "        total_loss = 0\n",
    "        all_preds, all_labels = [], []\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(self.device)\n",
    "            attention_mask = batch['attention_mask'].to(self.device)\n",
    "            labels = batch['labels'].to(self.device)\n",
    "            \n",
    "            outputs = self.model(input_ids, attention_mask)\n",
    "            loss = self.criterion(outputs, labels)\n",
    "            \n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(outputs, dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "        \n",
    "        # Calculate metrics\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            all_labels, all_preds, average='weighted'\n",
    "        )\n",
    "        \n",
    "        # Per-class metrics\n",
    "        per_class_precision, per_class_recall, per_class_f1, _ = precision_recall_fscore_support(\n",
    "            all_labels, all_preds, average=None\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'loss': total_loss / len(dataloader),\n",
    "            'accuracy': accuracy_score(all_labels, all_preds),\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1,\n",
    "            'per_class_f1': per_class_f1,\n",
    "            'predictions': all_preds,\n",
    "            'labels': all_labels\n",
    "        }\n",
    "    \n",
    "    def train(self) -> Dict:\n",
    "        \"\"\"Full training loop for all epochs.\"\"\"\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"Training: {self.model_name}\")\n",
    "        print(f\"{'='*60}\")\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for epoch in range(self.config.epochs):\n",
    "            print(f\"\\nEpoch {epoch + 1}/{self.config.epochs}\")\n",
    "            \n",
    "            # Train epoch\n",
    "            train_loss, train_acc = self.train_epoch()\n",
    "            \n",
    "            # Evaluate on validation set\n",
    "            val_results = self.evaluate(self.val_loader)\n",
    "            \n",
    "            # Record metrics\n",
    "            self.history['train_loss'].append(train_loss)\n",
    "            self.history['train_acc'].append(train_acc)\n",
    "            self.history['val_loss'].append(val_results['loss'])\n",
    "            self.history['val_acc'].append(val_results['accuracy'])\n",
    "            self.history['val_f1'].append(val_results['f1'])\n",
    "            \n",
    "            print(f\"  Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.4f}\")\n",
    "            print(f\"  Val Loss: {val_results['loss']:.4f} | Val Acc: {val_results['accuracy']:.4f} | Val F1: {val_results['f1']:.4f}\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_results['f1'] > self.best_val_f1:\n",
    "                self.best_val_f1 = val_results['f1']\n",
    "                torch.save(self.model.state_dict(), f'best_{self.model_name}.pt')\n",
    "                print(f\"  âœ“ Best model saved (F1: {self.best_val_f1:.4f})\")\n",
    "        \n",
    "        self.training_time = time.time() - start_time\n",
    "        print(f\"\\nâœ“ Training complete in {self.training_time:.1f}s\")\n",
    "        \n",
    "        return dict(self.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6476c8bd",
   "metadata": {},
   "source": [
    "## 6. ðŸ”µ Fine-tune BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fb77e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# BERT TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"Loading BERT tokenizer and model: {config.bert_model}\")\n",
    "\n",
    "# Load tokenizer\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(config.bert_model)\n",
    "\n",
    "# Create datasets\n",
    "bert_train_dataset = TextClassificationDataset(\n",
    "    train_dataset['text'], train_dataset['label'], \n",
    "    bert_tokenizer, config.max_length\n",
    ")\n",
    "bert_val_dataset = TextClassificationDataset(\n",
    "    val_dataset['text'], val_dataset['label'], \n",
    "    bert_tokenizer, config.max_length\n",
    ")\n",
    "bert_test_dataset = TextClassificationDataset(\n",
    "    test_dataset['text'], test_dataset['label'], \n",
    "    bert_tokenizer, config.max_length\n",
    ")\n",
    "\n",
    "# Create dataloaders\n",
    "bert_train_loader = DataLoader(bert_train_dataset, batch_size=config.batch_size, shuffle=True)\n",
    "bert_val_loader = DataLoader(bert_val_dataset, batch_size=config.batch_size * 2)\n",
    "bert_test_loader = DataLoader(bert_test_dataset, batch_size=config.batch_size * 2)\n",
    "\n",
    "print(f\"Train batches: {len(bert_train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cefd2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "bert_model = TransformerClassifier(\n",
    "    model_name=config.bert_model,\n",
    "    num_classes=config.num_classes,\n",
    "    dropout=config.dropout,\n",
    "    pooling=\"cls\"\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in bert_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in bert_model.parameters() if p.requires_grad)\n",
    "print(f\"\\nBERT Parameters:\")\n",
    "print(f\"  Total: {total_params:,}\")\n",
    "print(f\"  Trainable: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65455db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train BERT\n",
    "bert_trainer = Trainer(\n",
    "    model=bert_model,\n",
    "    train_loader=bert_train_loader,\n",
    "    val_loader=bert_val_loader,\n",
    "    config=config,\n",
    "    device=device,\n",
    "    model_name=\"BERT\"\n",
    ")\n",
    "\n",
    "bert_history = bert_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f997320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate BERT on test set\n",
    "bert_model.load_state_dict(torch.load('best_BERT.pt'))\n",
    "bert_test_results = bert_trainer.evaluate(bert_test_loader)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"BERT - TEST RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Accuracy:  {bert_test_results['accuracy']:.4f}\")\n",
    "print(f\"Precision: {bert_test_results['precision']:.4f}\")\n",
    "print(f\"Recall:    {bert_test_results['recall']:.4f}\")\n",
    "print(f\"F1 Score:  {bert_test_results['f1']:.4f}\")\n",
    "print(f\"\\nPer-emotion F1 scores:\")\n",
    "for i, name in enumerate(config.class_names):\n",
    "    print(f\"  {name:10} F1: {bert_test_results['per_class_f1'][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9694b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training time before clearing memory\n",
    "bert_training_time = bert_trainer.training_time\n",
    "\n",
    "# Clear GPU memory\n",
    "del bert_model\n",
    "del bert_trainer\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(\"Memory cleared for Qwen training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db24b531",
   "metadata": {},
   "source": [
    "## 7. ðŸŸ£ Fine-tune Qwen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53294a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# QWEN TRAINING\n",
    "# ============================================================================\n",
    "\n",
    "print(f\"Loading Qwen tokenizer and model: {config.qwen_model}\")\n",
    "\n",
    "# Load tokenizer\n",
    "qwen_tokenizer = AutoTokenizer.from_pretrained(config.qwen_model, trust_remote_code=True)\n",
    "if qwen_tokenizer.pad_token is None:\n",
    "    qwen_tokenizer.pad_token = qwen_tokenizer.eos_token\n",
    "\n",
    "# Create datasets\n",
    "qwen_train_dataset = TextClassificationDataset(\n",
    "    train_dataset['text'], train_dataset['label'], \n",
    "    qwen_tokenizer, config.max_length\n",
    ")\n",
    "qwen_val_dataset = TextClassificationDataset(\n",
    "    val_dataset['text'], val_dataset['label'], \n",
    "    qwen_tokenizer, config.max_length\n",
    ")\n",
    "qwen_test_dataset = TextClassificationDataset(\n",
    "    test_dataset['text'], test_dataset['label'], \n",
    "    qwen_tokenizer, config.max_length\n",
    ")\n",
    "\n",
    "# Smaller batch size for Qwen (larger model)\n",
    "qwen_batch_size = 8\n",
    "qwen_train_loader = DataLoader(qwen_train_dataset, batch_size=qwen_batch_size, shuffle=True)\n",
    "qwen_val_loader = DataLoader(qwen_val_dataset, batch_size=qwen_batch_size * 2)\n",
    "qwen_test_loader = DataLoader(qwen_test_dataset, batch_size=qwen_batch_size * 2)\n",
    "\n",
    "print(f\"Train batches: {len(qwen_train_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00726b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "qwen_model = TransformerClassifier(\n",
    "    model_name=config.qwen_model,\n",
    "    num_classes=config.num_classes,\n",
    "    dropout=config.dropout,\n",
    "    pooling=\"mean\",\n",
    "    trust_remote_code=True\n",
    ").to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in qwen_model.parameters())\n",
    "trainable_params = sum(p.numel() for p in qwen_model.parameters() if p.requires_grad)\n",
    "print(f\"\\nQwen Parameters:\")\n",
    "print(f\"  Total: {total_params:,}\")\n",
    "print(f\"  Trainable: {trainable_params:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d0fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Qwen (with adjusted config)\n",
    "qwen_config = Config()\n",
    "qwen_config.batch_size = qwen_batch_size\n",
    "qwen_config.learning_rate = 1e-5  # Lower LR for larger model\n",
    "\n",
    "qwen_trainer = Trainer(\n",
    "    model=qwen_model,\n",
    "    train_loader=qwen_train_loader,\n",
    "    val_loader=qwen_val_loader,\n",
    "    config=qwen_config,\n",
    "    device=device,\n",
    "    model_name=\"Qwen\"\n",
    ")\n",
    "\n",
    "qwen_history = qwen_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6307c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Qwen on test set\n",
    "qwen_model.load_state_dict(torch.load('best_Qwen.pt'))\n",
    "qwen_test_results = qwen_trainer.evaluate(qwen_test_loader)\n",
    "\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"QWEN - TEST RESULTS\")\n",
    "print(f\"{'='*50}\")\n",
    "print(f\"Accuracy:  {qwen_test_results['accuracy']:.4f}\")\n",
    "print(f\"Precision: {qwen_test_results['precision']:.4f}\")\n",
    "print(f\"Recall:    {qwen_test_results['recall']:.4f}\")\n",
    "print(f\"F1 Score:  {qwen_test_results['f1']:.4f}\")\n",
    "print(f\"\\nPer-emotion F1 scores:\")\n",
    "for i, name in enumerate(config.class_names):\n",
    "    print(f\"  {name:10} F1: {qwen_test_results['per_class_f1'][i]:.4f}\")\n",
    "\n",
    "# Save training time before it gets deleted\n",
    "qwen_training_time = qwen_trainer.training_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0370ee11",
   "metadata": {},
   "source": [
    "## 8. ðŸ“Š Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eff5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPARISON TABLE\n",
    "# ============================================================================\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_data = {\n",
    "    'Model': ['BERT', 'Qwen'],\n",
    "    'Accuracy': [bert_test_results['accuracy'], qwen_test_results['accuracy']],\n",
    "    'Precision': [bert_test_results['precision'], qwen_test_results['precision']],\n",
    "    'Recall': [bert_test_results['recall'], qwen_test_results['recall']],\n",
    "    'F1 Score': [bert_test_results['f1'], qwen_test_results['f1']],\n",
    "    'Training Time (s)': [bert_training_time, qwen_training_time]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.round(4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" \" * 20 + \"MODEL COMPARISON\")\n",
    "print(\"=\"*70)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Determine winner\n",
    "winner = 'BERT' if bert_test_results['f1'] > qwen_test_results['f1'] else 'Qwen'\n",
    "diff = abs(bert_test_results['f1'] - qwen_test_results['f1'])\n",
    "print(f\"\\nðŸ† Winner: {winner} (F1 difference: {diff:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6a46ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# VISUALIZATION: Performance Comparison\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# 1. Overall Metrics Comparison (Bar chart)\n",
    "metrics = ['Accuracy', 'Precision', 'Recall', 'F1 Score']\n",
    "bert_scores = [bert_test_results['accuracy'], bert_test_results['precision'], \n",
    "               bert_test_results['recall'], bert_test_results['f1']]\n",
    "qwen_scores = [qwen_test_results['accuracy'], qwen_test_results['precision'], \n",
    "               qwen_test_results['recall'], qwen_test_results['f1']]\n",
    "\n",
    "x = np.arange(len(metrics))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = axes[0, 0].bar(x - width/2, bert_scores, width, label='BERT', color='#3498db')\n",
    "bars2 = axes[0, 0].bar(x + width/2, qwen_scores, width, label='Qwen', color='#9b59b6')\n",
    "axes[0, 0].set_ylabel('Score')\n",
    "axes[0, 0].set_title('Overall Performance Metrics', fontsize=14, fontweight='bold')\n",
    "axes[0, 0].set_xticks(x)\n",
    "axes[0, 0].set_xticklabels(metrics)\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].set_ylim(0, 1)\n",
    "axes[0, 0].axhline(y=0.5, color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, score in zip(bars1, bert_scores):\n",
    "    axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                    f'{score:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "for bar, score in zip(bars2, qwen_scores):\n",
    "    axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                    f'{score:.3f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 2. Per-Class F1 Comparison\n",
    "x = np.arange(len(config.class_names))\n",
    "bars1 = axes[0, 1].bar(x - width/2, bert_test_results['per_class_f1'], width, label='BERT', color='#3498db')\n",
    "bars2 = axes[0, 1].bar(x + width/2, qwen_test_results['per_class_f1'], width, label='Qwen', color='#9b59b6')\n",
    "axes[0, 1].set_ylabel('F1 Score')\n",
    "axes[0, 1].set_title('Per-Emotion F1 Scores', fontsize=14, fontweight='bold')\n",
    "axes[0, 1].set_xticks(x)\n",
    "axes[0, 1].set_xticklabels(config.class_names, rotation=45)\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].set_ylim(0, 1)\n",
    "\n",
    "# 3. Training History - Loss\n",
    "epochs_range = range(1, config.epochs + 1)\n",
    "axes[1, 0].plot(epochs_range, bert_history['val_loss'], 'b-o', label='BERT Val Loss', linewidth=2)\n",
    "axes[1, 0].plot(epochs_range, qwen_history['val_loss'], 'm-o', label='Qwen Val Loss', linewidth=2)\n",
    "axes[1, 0].set_xlabel('Epoch')\n",
    "axes[1, 0].set_ylabel('Loss')\n",
    "axes[1, 0].set_title('Validation Loss During Training', fontsize=14, fontweight='bold')\n",
    "axes[1, 0].legend()\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Training History - F1\n",
    "axes[1, 1].plot(epochs_range, bert_history['val_f1'], 'b-o', label='BERT Val F1', linewidth=2)\n",
    "axes[1, 1].plot(epochs_range, qwen_history['val_f1'], 'm-o', label='Qwen Val F1', linewidth=2)\n",
    "axes[1, 1].set_xlabel('Epoch')\n",
    "axes[1, 1].set_ylabel('F1 Score')\n",
    "axes[1, 1].set_title('Validation F1 During Training', fontsize=14, fontweight='bold')\n",
    "axes[1, 1].legend()\n",
    "axes[1, 1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('emotion_model_comparison.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Comparison visualization saved as 'emotion_model_comparison.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b4411c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CONFUSION MATRICES\n",
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# BERT Confusion Matrix\n",
    "cm_bert = confusion_matrix(bert_test_results['labels'], bert_test_results['predictions'])\n",
    "sns.heatmap(cm_bert, annot=True, fmt='d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=config.class_names, yticklabels=config.class_names)\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_title(f'BERT Confusion Matrix\\nAccuracy: {bert_test_results[\"accuracy\"]:.4f}', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "\n",
    "# Qwen Confusion Matrix\n",
    "cm_qwen = confusion_matrix(qwen_test_results['labels'], qwen_test_results['predictions'])\n",
    "sns.heatmap(cm_qwen, annot=True, fmt='d', cmap='Purples', ax=axes[1],\n",
    "            xticklabels=config.class_names, yticklabels=config.class_names)\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "axes[1].set_title(f'Qwen Confusion Matrix\\nAccuracy: {qwen_test_results[\"accuracy\"]:.4f}', \n",
    "                  fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('emotion_confusion_matrices.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nâœ“ Confusion matrices saved as 'emotion_confusion_matrices.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b55c0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# DETAILED CLASSIFICATION REPORTS\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" \" * 15 + \"BERT CLASSIFICATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(bert_test_results['labels'], bert_test_results['predictions'], \n",
    "                            target_names=config.class_names))\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\" \" * 15 + \"QWEN CLASSIFICATION REPORT\")\n",
    "print(\"=\"*70)\n",
    "print(classification_report(qwen_test_results['labels'], qwen_test_results['predictions'], \n",
    "                            target_names=config.class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1987fada",
   "metadata": {},
   "source": [
    "## 9. ðŸ”® Inference Examples\n",
    "\n",
    "Test emotion prediction on new texts with both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91391366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# INFERENCE FUNCTION\n",
    "# ============================================================================\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_emotion(text: str, model, tokenizer, device, class_names):\n",
    "    \"\"\"Predict emotion for a given text.\n",
    "    \n",
    "    Args:\n",
    "        text: Input text to classify\n",
    "        model: Trained transformer classifier\n",
    "        tokenizer: Tokenizer matching the model\n",
    "        device: Device to run inference on\n",
    "        class_names: List of emotion class names\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with predictions and confidence scores\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    \n",
    "    # Tokenize input text\n",
    "    encoding = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        max_length=config.max_length,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Get predictions\n",
    "    outputs = model(input_ids, attention_mask)\n",
    "    probs = F.softmax(outputs, dim=1)\n",
    "    pred = torch.argmax(probs, dim=1).item()\n",
    "    confidence = probs[0][pred].item()\n",
    "    \n",
    "    return {\n",
    "        'prediction': class_names[pred],\n",
    "        'confidence': confidence,\n",
    "        'all_probs': {name: probs[0][i].item() for i, name in enumerate(class_names)}\n",
    "    }\n",
    "\n",
    "\n",
    "def compare_predictions(text: str):\n",
    "    \"\"\"Compare BERT and Qwen predictions for a text.\"\"\"\n",
    "    # Get predictions from both models\n",
    "    bert_result = predict_emotion(text, bert_model, bert_tokenizer, device, config.class_names)\n",
    "    qwen_result = predict_emotion(text, qwen_model, qwen_tokenizer, device, config.class_names)\n",
    "    \n",
    "    # Display results\n",
    "    print(f\"\\nText: \\\"{text[:100]}{'...' if len(text) > 100 else ''}\\\"\")\n",
    "    print(f\"\\n  BERT: {bert_result['prediction']:10} ({bert_result['confidence']:.1%} confidence)\")\n",
    "    print(f\"  Qwen: {qwen_result['prediction']:10} ({qwen_result['confidence']:.1%} confidence)\")\n",
    "    \n",
    "    if bert_result['prediction'] == qwen_result['prediction']:\n",
    "        print(f\"  âœ… Both models agree!\")\n",
    "    else:\n",
    "        print(f\"  âš ï¸ Models disagree!\")\n",
    "    \n",
    "    return bert_result, qwen_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820d8481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best models for inference\n",
    "bert_model = TransformerClassifier(config.bert_model, config.num_classes, config.dropout, \"cls\").to(device)\n",
    "bert_model.load_state_dict(torch.load('best_BERT.pt'))\n",
    "\n",
    "print(\"âœ“ Best models loaded for inference\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1c4cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with diverse examples\n",
    "test_samples = [\n",
    "    \"I absolutely love this moment with you!\",  # joy/love\n",
    "    \"This is the most terrible day of my life.\",  # sadness\n",
    "    \"I cannot believe you did this to me!\",  # anger\n",
    "    \"I'm so excited for the party tonight!\",  # joy\n",
    "    \"I'm terrified of what might happen.\",  # fear\n",
    "    \"What an unexpected turn of events!\",  # surprise\n",
    "    \"You are the love of my life.\",  # love\n",
    "    \"I feel so lonely and empty inside.\",  # sadness\n",
    "]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\" \" * 20 + \"EMOTION PREDICTION EXAMPLES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for text in test_samples:\n",
    "    compare_predictions(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168e144a",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ðŸ“ Summary & Key Takeaways\n",
    "\n",
    "### Experiment Overview\n",
    "\n",
    "This notebook demonstrates fine-tuning **BERT** and **Qwen** for **emotion classification** on the official Emotion dataset from HuggingFace with **6 emotion classes**.\n",
    "\n",
    "### Models Compared\n",
    "\n",
    "| Model | Architecture | Size | Pooling |\n",
    "|-------|--------------|------|----------|\n",
    "| BERT-base-uncased | Encoder-only | ~110M | CLS token |\n",
    "| Qwen2.5-0.5B | Decoder-only (LLM) | ~500M | Mean pooling |\n",
    "\n",
    "### Dataset\n",
    "\n",
    "- **Name**: Emotion (HuggingFace)\n",
    "- **Classes**: 6 (sadness, joy, love, anger, fear, surprise)\n",
    "- **Train size**: 12,000 samples\n",
    "- **Test size**: 2,000 samples\n",
    "\n",
    "### Key Observations\n",
    "\n",
    "1. **BERT** is typically more efficient for classification tasks due to its encoder-only architecture\n",
    "2. **Qwen** requires more GPU memory but brings knowledge from large-scale pretraining\n",
    "3. Both models handle multiclass emotion classification effectively\n",
    "4. Training time and convergence speed depend on dataset size and hardware\n",
    "\n",
    "### Results\n",
    "\n",
    "Check the comparison tables and visualizations above to see which model performs better for emotion classification!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
